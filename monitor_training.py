#!/usr/bin/env python
# coding=utf-8
"""
å®æ—¶ç›‘æ§è®­ç»ƒè¿›åº¦
åœ¨äº‘æœåŠ¡å™¨ä¸Šè¿è¡Œè®­ç»ƒæ—¶ï¼Œä½¿ç”¨æ­¤è„šæœ¬æŸ¥çœ‹å®æ—¶çŠ¶æ€
"""

import os
import sys
import json
import time
import argparse
from pathlib import Path
from datetime import datetime


def parse_trainer_state(state_file: str) -> dict:
    """è§£ætrainer_state.json"""
    if not os.path.exists(state_file):
        return None

    with open(state_file, 'r') as f:
        state = json.load(f)

    return state


def format_time(seconds: float) -> str:
    """æ ¼å¼åŒ–æ—¶é—´"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    return f"{hours:02d}:{minutes:02d}:{secs:02d}"


def estimate_remaining_time(state: dict) -> str:
    """ä¼°ç®—å‰©ä½™æ—¶é—´"""
    if "train_runtime" not in state or "global_step" not in state:
        return "æœªçŸ¥"

    runtime = state["train_runtime"]
    current_step = state["global_step"]
    max_steps = state.get("max_steps", 0)

    if max_steps == 0 or current_step == 0:
        return "æœªçŸ¥"

    avg_time_per_step = runtime / current_step
    remaining_steps = max_steps - current_step
    remaining_seconds = avg_time_per_step * remaining_steps

    return format_time(remaining_seconds)


def get_latest_metrics(state: dict) -> dict:
    """è·å–æœ€æ–°æŒ‡æ ‡"""
    if "log_history" not in state or len(state["log_history"]) == 0:
        return {}

    return state["log_history"][-1]


def get_best_metrics(state: dict) -> dict:
    """è·å–æœ€ä½³æŒ‡æ ‡"""
    log_history = state.get("log_history", [])

    best_metrics = {}
    best_f1 = -1
    best_loss = float('inf')

    for log in log_history:
        # æŸ¥æ‰¾æœ€ä½³F1
        for key in ["eval_f1", "eval_overall_f1"]:
            if key in log and log[key] > best_f1:
                best_f1 = log[key]
                best_metrics["best_f1"] = best_f1
                best_metrics["best_f1_step"] = log.get("step", 0)

        # æŸ¥æ‰¾æœ€ä½loss
        if "loss" in log and log["loss"] < best_loss:
            best_loss = log["loss"]
            best_metrics["best_loss"] = best_loss
            best_metrics["best_loss_step"] = log.get("step", 0)

    return best_metrics


def print_status(output_dir: str, clear_screen: bool = True):
    """æ‰“å°è®­ç»ƒçŠ¶æ€"""
    state_file = os.path.join(output_dir, "trainer_state.json")

    if clear_screen:
        os.system('clear' if os.name != 'nt' else 'cls')

    print("=" * 80)
    print(f"HRDoc è®­ç»ƒç›‘æ§ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 80)

    state = parse_trainer_state(state_file)

    if state is None:
        print("\nâš ï¸  è®­ç»ƒå°šæœªå¼€å§‹æˆ–çŠ¶æ€æ–‡ä»¶ä¸å­˜åœ¨")
        print(f"   ç›‘æ§ç›®å½•: {output_dir}")
        return False

    # åŸºæœ¬ä¿¡æ¯
    print(f"\nğŸ“Š è®­ç»ƒè¿›åº¦:")
    current_step = state.get("global_step", 0)
    max_steps = state.get("max_steps", 0)
    epoch = state.get("epoch", 0)

    if max_steps > 0:
        progress = (current_step / max_steps) * 100
        print(f"   å½“å‰æ­¥æ•°: {current_step:,} / {max_steps:,} ({progress:.1f}%)")
    else:
        print(f"   å½“å‰æ­¥æ•°: {current_step:,}")

    print(f"   å½“å‰Epoch: {epoch:.2f}")

    # æ—¶é—´ä¿¡æ¯
    if "train_runtime" in state:
        runtime = state["train_runtime"]
        print(f"\nâ±ï¸  æ—¶é—´ä¿¡æ¯:")
        print(f"   å·²è¿è¡Œæ—¶é—´: {format_time(runtime)}")
        remaining = estimate_remaining_time(state)
        print(f"   é¢„è®¡å‰©ä½™: {remaining}")

        # è®­ç»ƒé€Ÿåº¦
        if current_step > 0:
            samples_per_sec = state.get("train_samples_per_second", 0)
            steps_per_sec = current_step / runtime
            print(f"   è®­ç»ƒé€Ÿåº¦: {samples_per_sec:.4f} samples/sec, {steps_per_sec:.4f} steps/sec")

    # æœ€æ–°æŒ‡æ ‡
    latest_metrics = get_latest_metrics(state)
    if latest_metrics:
        print(f"\nğŸ“ˆ æœ€æ–°æŒ‡æ ‡ (Step {latest_metrics.get('step', 0)}):")

        # Loss
        if "loss" in latest_metrics:
            print(f"   Loss: {latest_metrics['loss']:.4f}")

        # å­¦ä¹ ç‡
        if "learning_rate" in latest_metrics:
            print(f"   Learning Rate: {latest_metrics['learning_rate']:.2e}")

        # è¯„ä¼°æŒ‡æ ‡
        for key in ["eval_f1", "eval_precision", "eval_recall", "eval_accuracy"]:
            if key in latest_metrics:
                metric_name = key.replace("eval_", "").upper()
                print(f"   {metric_name}: {latest_metrics[key]:.4f}")

    # æœ€ä½³æŒ‡æ ‡
    best_metrics = get_best_metrics(state)
    if best_metrics:
        print(f"\nğŸ† æœ€ä½³æŒ‡æ ‡:")
        if "best_f1" in best_metrics:
            print(f"   Best F1: {best_metrics['best_f1']:.4f} (Step {best_metrics['best_f1_step']})")
        if "best_loss" in best_metrics:
            print(f"   Best Loss: {best_metrics['best_loss']:.4f} (Step {best_metrics['best_loss_step']})")

    # æ£€æŸ¥å¼‚å¸¸
    warnings = check_anomalies(state, latest_metrics)
    if warnings:
        print(f"\nâš ï¸  å¼‚å¸¸æ£€æµ‹:")
        for warning in warnings:
            print(f"   {warning}")

    print("\n" + "=" * 80)
    print("æŒ‰ Ctrl+C é€€å‡ºç›‘æ§")
    print("=" * 80)

    return True


def check_anomalies(state: dict, latest_metrics: dict) -> list:
    """æ£€æµ‹è®­ç»ƒå¼‚å¸¸"""
    warnings = []

    # æ£€æŸ¥lossæ˜¯å¦ä¸ºNaN
    if "loss" in latest_metrics:
        loss = latest_metrics["loss"]
        if loss != loss:  # NaNæ£€æµ‹
            warnings.append("âš ï¸ Loss is NaN! è®­ç»ƒå¯èƒ½å·²å´©æºƒ")
        elif loss > 10.0:
            warnings.append(f"âš ï¸ Lossè¿‡é«˜: {loss:.4f}")

    # æ£€æŸ¥F1æ˜¯å¦è¿‡ä½
    if "eval_f1" in latest_metrics:
        f1 = latest_metrics["eval_f1"]
        current_step = state.get("global_step", 0)
        if current_step > 1000 and f1 < 0.5:
            warnings.append(f"âš ï¸ F1è¿‡ä½: {f1:.4f} (Step {current_step})")

    # æ£€æŸ¥è®­ç»ƒé€Ÿåº¦
    if "train_samples_per_second" in latest_metrics:
        speed = latest_metrics["train_samples_per_second"]
        if speed < 0.05:
            warnings.append(f"âš ï¸ è®­ç»ƒé€Ÿåº¦è¿‡æ…¢: {speed:.4f} samples/sec")

    # æ£€æŸ¥æ˜¯å¦å¡ä½
    current_step = state.get("global_step", 0)
    max_steps = state.get("max_steps", 0)
    if max_steps > 0 and current_step == 0:
        warnings.append("âš ï¸ è®­ç»ƒå°šæœªå¼€å§‹")

    return warnings


def monitor_loop(output_dir: str, interval: int = 10):
    """ç›‘æ§å¾ªç¯"""
    try:
        while True:
            success = print_status(output_dir, clear_screen=True)
            if not success:
                print(f"\nç­‰å¾…è®­ç»ƒå¼€å§‹... (æ¯{interval}ç§’åˆ·æ–°)")

            time.sleep(interval)

    except KeyboardInterrupt:
        print("\n\nç›‘æ§å·²åœæ­¢")


def main():
    parser = argparse.ArgumentParser(description="å®æ—¶ç›‘æ§HRDocè®­ç»ƒè¿›åº¦")
    parser.add_argument(
        "--output-dir",
        type=str,
        default="./output/hrdoc_simple_full",
        help="è®­ç»ƒè¾“å‡ºç›®å½•"
    )
    parser.add_argument(
        "--interval",
        type=int,
        default=10,
        help="åˆ·æ–°é—´éš”ï¼ˆç§’ï¼‰"
    )
    parser.add_argument(
        "--once",
        action="store_true",
        help="åªæ˜¾ç¤ºä¸€æ¬¡ï¼Œä¸å¾ªç¯"
    )

    args = parser.parse_args()

    if args.once:
        print_status(args.output_dir, clear_screen=False)
    else:
        monitor_loop(args.output_dir, args.interval)


if __name__ == "__main__":
    main()
