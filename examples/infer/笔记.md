```shell
python examples/infer/run_stage1_infer.py --env test --dataset hrds --max_test_samples 500 
--max_test_samples 500 
--quick
--model_path

python examples/infer/run_stage1_infer.py --env test --dataset hrds --max_test_samples 500 --model_path /data/LLM_group/layoutlmft/artifact/exp_20251210_201220/stage1_hrdh/checkpoint-30000

conda run -n layoutlmv2 python examples/infer/util/pdf_extractor.py # 将pdf转为推理所需的数据

```

```shell
 python examples/evaluate/run_classify_eval.py --env test --dataset hrdh
```


Title	Author	Mail	Affili	Section	Fstline	Paraline	Table	Figure	Caption	Equation	Footer	Header	Footnote


 联合训练推理需要的输入

  batch = {
      "input_ids":      # text 分词后的 token ids
      "bbox":           # 规范化后的边界框 (每个token一个)
      "attention_mask": # 注意力掩码
      "image":          # 页面图像 (224x224)
      "line_ids":       # 每个 token 对应的 line_id (关键！用于聚合)
  }

  数据转换流程

  原始数据                    模型输入
  ─────────                  ─────────
  text ──→ tokenize ──→ input_ids, attention_mask
  box  ──→ 规范化+对齐 ──→ bbox (每个token一个)
  page ──→ (输出用)
  line_id ──→ 扩展到token级别 ──→ line_ids (每个token标记属于哪一行)
  image ──→ 加载+resize ──→ image

  关键：line_ids 的作用

  # 原始数据（行级别）
  lines = [
      {"text": "Hello world", "line_id": 0},
      {"text": "This is test", "line_id": 1},
  ]

  # tokenize 后（token级别）
  tokens = ["Hello", "world", "This", "is", "test"]
  line_ids = [0, 0, 1, 1, 1]  # 每个token属于哪一行

  # 模型推理后，用 line_ids 把 token 预测聚合回行级别

  所以你说得对，核心就是 text, box, page, line_id，但传给模型前需要：
  1. text → 分词成 input_ids
  2. box → 扩展到每个 token
  3. line_id → 扩展到每个 token（line_ids）
  4. 加上 image


# 自己实现

  | 阶段    | 输入                | 来源                         |
  |---------|---------------------|------------------------------|
  | Stage 1 | tokens, bbox, image | PDF解析 + tokenize           |
  | Stage 3 | line_features       | Stage 1 输出 + line_ids 聚合 |
  | Stage 4 | parent/child 特征对 | Stage 3 的 gru_hidden        |

阶段1：json的text,box 和 图片
line_id在构造数据的时候也带上
stage2提取行特征的时候会需要line_id