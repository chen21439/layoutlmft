

# 4.2. Detect Module (检测模块)

**English:**
The proposed Detect module consists of three primary components: 1) A shared visual backbone network designed to extract multi-scale feature maps from input document images; 2) A top-down graphical page object detection model for detecting graphical page objects, such as tables, figures, and displayed formulas; 3) A bottom-up text region detection model that groups text-lines located outside graphical page objects into text regions, based on the intra-region reading order, and identifies the logical role of each text region.

**Chinese:**
所提出的检测模块（Detect module）由三个主要部分组成：1）一个共享的视觉骨干网络，用于从输入文档图像中提取多尺度特征图；2）一个自顶向下的图形页面对象检测模型，用于检测图形页面对象，如表格、插图和独立公式；3）一个自底向上的文本区域检测模型，该模型根据区域内的阅读顺序，将位于图形页面对象之外的文本行分组为文本区域，并识别每个文本区域的逻辑角色。

**English:**
The overall architecture of the Detect module is illustrated in Fig. 3. In our conference paper [10], we selected a ResNet-50 network as the backbone network to generate multi-scale feature maps and the DINO [69] as the top-down graphical page object detector to localize these graphical objects. However, any suitable visual backbone network and object detection or instance segmentation model can be readily incorporated into our Detect module.

**Chinese:**
检测模块的整体架构如图 3 所示。在我们的会议论文 [10] 中，我们选择 ResNet-50 网络作为骨干网络来生成多尺度特征图，并使用 DINO [69] 作为自顶向下的图形页面对象检测器来定位这些图形对象。然而，任何合适的视觉骨干网络和目标检测或实例分割模型都可以很容易地集成到我们的检测模块中。

**English:**
In this paper, we primarily concentrate on the details of the newly proposed Bottom-up Text Region Detection Model. A text region is a semantic unit of writing that comprises a group of text-lines arranged in natural reading order and associated with a logical label, such as paragraph, list/list-item, title, section heading, header, footer, footnote, and caption.

**Chinese:**
在本文中，我们主要关注新提出的“自底向上文本区域检测模型”的细节。文本区域是一个书写语义单元，由一组按自然阅读顺序排列的文本行组成，并关联一个逻辑标签，如段落、列表/列表项、标题、章节标题、页眉、页脚、脚注和说明文字。

**English:**
Given a document page rendering  composed of  text-lines , the objective of our bottom-up text region detection model is to group these text-lines into distinct text regions according to the intra-region reading order and to recognize the logical role of each text region.

**Chinese:**
给定一个由  个文本行  组成的文档页面渲染 ，我们自底向上文本区域检测模型的目标是根据区域内阅读顺序将这些文本行分组为不同的文本区域，并识别每个文本区域的逻辑角色。

**English:**
In this study, we assume that the bounding boxes and textual contents of text-lines have already been provided by a PDF parser or OCR engine. Based on the detection results of the top-down graphical page object detection model, we initially filter out those text-lines located inside graphical page objects and then utilize the remaining text-lines as input.

**Chinese:**
在本研究中，我们假设文本行的边界框和文本内容已由 PDF 解析器或 OCR 引擎提供。基于自顶向下图形页面对象检测模型的检测结果，我们首先过滤掉那些位于图形页面对象内部的文本行，然后利用剩余的文本行作为输入。

**English:**
As depicted in Fig. 4, our bottom-up text region detection model consists of a multi-modal feature extraction module, a multi-modal feature enhancement module, and two prediction heads, i.e., an intra-region reading order relation prediction head and a logical role classification head. The detailed illustrations of the multi-modal feature enhancement module and the two prediction heads can be found in Fig. 5.

**Chinese:**
如图 4 所示，我们的自底向上文本区域检测模型包括一个多模态特征提取模块、一个多模态特征增强模块和两个预测头，即区域内阅读顺序关系预测头和逻辑角色分类头。多模态特征增强模块和这两个预测头的详细示意图见图 5。

---

### 4.2.1. Multi-modal Feature Extraction Module (多模态特征提取模块)

**English:**
In this module, we extract the visual embedding, text embedding, and 2D Positional Embedding for each text-line.

**Chinese:**
在该模块中，我们为每个文本行提取视觉嵌入、文本嵌入和 2D 位置嵌入。

**English:**
**Visual Embedding.** As shown in Fig. 4, we first resize  and  to the size of  and then concatenate these three feature maps along the channel axis, which are fed into a  convolutional layer to generate a feature map  with 256 channels. For each text-line , we adopt the RoIAlign algorithm [6] to extract  feature maps from  based on its bounding box  where ,  represent the coordinates of its upper left and bottom right corners, respectively. The final visual embedding  of  can be represented as:

**Chinese:**
**视觉嵌入**。如图 4 所示，我们首先将  和  调整为  的大小，然后沿通道轴拼接这三个特征图，将其输入到一个  卷积层中，生成具有 256 个通道的特征图 。对于每个文本行 ，我们采用 RoIAlign 算法 [6] 根据其边界框  从  中提取  的特征图，其中  和  分别代表其左上角和右下角的坐标。 的最终视觉嵌入  可表示为：

**English:**
where FC is a fully-connected layer with 1,024 nodes and LN represents Layer Normalization [70].

**Chinese:**
其中 FC 是一个拥有 1024 个节点的全连接层，LN 代表层归一化（Layer Normalization）[70]。

**English:**
**Text Embedding.** We leverage the pre-trained language model BERT [71] to extract the text embedding of each text-line. Specifically, we first serialize all the text-lines in a document image into a 1D sequence by reading them in a top-left to bottom-right order and tokenize the text-line sequence into a sub-word token sequence, which is then fed into BERT to get the embedding of each token. After that, we average the embeddings of all the tokens in each text-line  to obtain its text embedding  followed by a fully-connected layer with 1,024 nodes to make the dimension the same as that of :

**Chinese:**
**文本嵌入**。我们利用预训练语言模型 BERT [71] 来提取每个文本行的文本嵌入。具体来说，我们首先按照从左上到右下的顺序读取文档图像中的所有文本行，将其序列化为一维序列，并将该文本行序列分词为子词 token 序列，然后将其输入 BERT 以获取每个 token 的嵌入。之后，我们将每个文本行  中所有 token 的嵌入取平均值，以获得其文本嵌入 ，随后通过一个拥有 1024 个节点的全连接层，使其维度与  相同：

**English:**
**2D Positional Embedding.** For each text-line , we encode its bounding box and size information as its 2D Positional Embedding :

**Chinese:**
**2D 位置嵌入**。对于每个文本行 ，我们将其边界框和尺寸信息编码为其 2D 位置嵌入 ：

**English:**
where  and  represent the width and height of  and the input image, respectively. MLP consists of 2 fully-connected layers with 1,024 nodes, each of which is followed by ReLU.

**Chinese:**
其中  和  分别表示  的宽度和高度以及输入图像的宽度和高度。MLP 由 2 个拥有 1024 个节点的全连接层组成，每层之后都接一个 ReLU 激活函数。

**English:**
For each text-line  we concatenate its visual embedding , text embeddings , and 2D Positional Embedding  to obtain its multi-modal representation :

**Chinese:**
对于每个文本行 ，我们将它的视觉嵌入 、文本嵌入  和 2D 位置嵌入  进行拼接，以获得其多模态表示 ：

**English:**
where FC is a fully-connected layer with 1,024 nodes.

**Chinese:**
其中 FC 是一个拥有 1024 个节点的全连接层。

---

### 4.2.2. Multi-modal Feature Enhancement Module (多模态特征增强模块)

**English:**
As shown in Fig. 5, we use a lightweight Transformer encoder to further enhance the multi-modal representations of text-lines by modeling their interactions with a self-attention mechanism. Each text-line is treated as a token of the Transformer encoder and its multi-modal representation is taken as the input embedding:

**Chinese:**
如图 5 所示，我们使用一个轻量级 Transformer 编码器，通过自注意力机制对文本行之间的交互进行建模，从而进一步增强文本行的多模态表示。每个文本行被视为 Transformer 编码器的一个 token，其多模态表示被用作输入嵌入：

**English:**
where  and  are the input and output embeddings of the Transformer encoder,  is the number of the input text-lines. To save computation, here we only use a 1-layer Transformer encoder, where the head number, dimension of hidden state, and the dimension of feedforward network are set as 12, 768, and 2048, respectively.

**Chinese:**
其中  和  分别是 Transformer 编码器的输入和输出嵌入， 是输入文本行的数量。为了节省计算量，这里我们仅使用 1 层 Transformer 编码器，其中头数（head number）、隐藏状态维度（hidden state dimension）和前馈网络维度（feedforward network dimension）分别设置为 12、768 和 2048。

---

### 4.2.3. Intra-region Reading Order Relation Prediction Head (区域内阅读顺序关系预测头)

**English:**
We propose to use a relation prediction head to predict intra-region reading order relationships between text-lines. Given a text-line , if a text-line  is its succeeding text-line in the same text region, we define that there exists an intra-region reading order relationship  pointing from text-line  to text-line . If text-line  is the last (or only) text-line in a text region, its succeeding text-line is considered to be itself.

**Chinese:**
我们建议使用一个关系预测头来预测文本行之间的区域内阅读顺序关系。给定一个文本行 ，如果文本行  是其在同一文本区域中的后续文本行，我们定义存在一个指向从  到  的区域内阅读顺序关系 。如果文本行  是文本区域中的最后一行（或唯一一行），则其后续文本行被认为是它自己。

**English:**
Unlike many previous methods that consider relation prediction as a binary classification task [42, 45], we treat relation prediction as a dependency parsing task and use a softmax cross-entropy loss to replace the standard binary cross-entropy loss during optimization by following [72]. Moreover, we adopt a spatial compatibility feature introduced in [73] to effectively model spatial interactions between text-lines for relation prediction.

**Chinese:**
与许多将关系预测视为二分类任务的先前方法 [42, 45] 不同，我们参考 [72]，将关系预测视为依存句法分析任务，并在优化过程中使用 softmax 交叉熵损失来代替标准的二元交叉熵损失。此外，我们采用了 [73] 中介绍的空间兼容性特征（spatial compatibility feature），以有效地为关系预测建模文本行之间的空间交互。

**English:**
Specifically, we use a multi-class (i.e., n-class) classifier to calculate a score  to estimate how likely  is the succeeding text-line of  as follows:

**Chinese:**
具体来说，我们使用一个多类别（即 n 类）分类器来计算分数 ，以估计  成为  后续文本行的可能性，如下所示：

**English:**
where each of  and  is a single fully-connected layer with 2,048 nodes to map  and  into different feature spaces;  denotes dot product operation; MLP consists of 2 fully-connected layers with 1,024 nodes and 1 node respectively;  is a spatial compatibility feature vector between  and  which is a concatenation of three 6-d vectors:

**Chinese:**
其中  和  均为拥有 2048 个节点的单层全连接层，用于将  和  映射到不同的特征空间； 表示点积运算；MLP 由分别拥有 1024 个节点和 1 个节点的 2 层全连接层组成； 是  和  之间的空间兼容性特征向量，它由三个 6 维向量拼接而成：

**English:**
where  is the union bounding box of  and ;  represents the box delta between any two bounding boxes. Taking  as an example, , where each dimension is given by:

**Chinese:**
其中  是  和  的联合边界框（union bounding box）； 表示任意两个边界框之间的框差（box delta）。以  为例，，其中每个维度的计算方式为：

**English:**
where  and  are the center coordinates of  and , respectively. We select the highest score from scores  and output the corresponding text-line as the succeeding text-line of .

**Chinese:**
其中  和  分别是  和  的中心坐标。我们从分数  中选择最高分，并输出相应的文本行作为  的后续文本行。

**English:**
To achieve higher relation prediction accuracy for the intra-region reading order relationship, which has a chain structure, we employ an additional relation prediction head to further identify the preceding text-line for each text-line. The prediction results from both relation prediction heads are then combined to obtain the final results. Based on the predicted intra-region reading order relationships, we group text-lines into text regions using a Union-Find algorithm. The bounding box of the text region is the union bounding box of all its constituent text-lines.

**Chinese:**
为了在链式结构的区域内阅读顺序关系上获得更高的预测准确率，我们使用了一个额外的关系预测头来进一步识别每个文本行的前序文本行。然后结合两个关系预测头的预测结果以获得最终结果。基于预测的区域内阅读顺序关系，我们使用并查集（Union-Find）算法将文本行分组为文本区域。文本区域的边界框是其所有组成文本行的联合边界框。

---

### 4.2.4. Logical Role Classification Head (逻辑角色分类头)

**English:**
Given the enhanced multi-modal representations of text-lines , we add a multi-class classifier to predict a logical role label for each text-line and determine the logical role of each text region by the plurality voting of all its constituent text-lines.

**Chinese:**
给定增强后的文本行多模态表示 ，我们添加一个多类别分类器来预测每个文本行的逻辑角色标签，并通过其所有组成文本行的多数投票（plurality voting）来确定每个文本区域的逻辑角色。

# 4.3. Order Module (排序模块)

**English:**
The Order module focuses on determining the reading sequence of graphical page objects and text regions identified by the Detect module within document D. Similar to the bottom-up text region detection model employed in the Detect module, we also utilize our proposed multi-modal, transformer-based relation prediction model to predict the inter-region reading order relationships among the recognized page objects.

**Chinese:**
[cite_start]排序模块专注于确定检测模块在文档 D 中识别出的图形页面对象和文本区域的阅读顺序。与检测模块中采用的自底向上文本区域检测模型类似，我们也利用我们提出的多模态、基于 Transformer 的关系预测模型来预测已识别页面对象之间的区域间阅读顺序关系 [cite: 429]。

**English:**
The Order module processes the detected page objects as input and employs an attention-based approach to integrate the features of text-lines belonging to the same text region, thereby achieving a more efficient feature representation of the text region. Furthermore, we define two categories of inter-region reading order relationships: (1) Text region reading order relationships between main body text regions, (2) Graphical region reading order relationships between captions/footnotes and graphical page objects such as tables and figures.

**Chinese:**
[cite_start]排序模块将检测到的页面对象作为输入，并采用基于注意力的方法来整合属于同一文本区域的文本行的特征，从而实现对文本区域更高效的特征表示。此外，我们将区域间阅读顺序关系定义为两类：（1）正文文本区域之间的文本区域阅读顺序关系；（2）说明文字/脚注与图形页面对象（如表格和插图）之间的图形区域阅读顺序关系 [cite: 430, 431]。

**English:**
Consequently, we incorporate an additional inter-region reading order relation classification head to predict relation types. A detailed illustration of the Order module can be found in Fig. 6.

**Chinese:**
[cite_start]因此，我们引入了一个额外的区域间阅读顺序关系分类头来预测关系类型。排序模块的详细示意图见图 6 [cite: 432, 433]。

---

### 4.3.1. Multi-modal Feature Extraction Module (多模态特征提取模块)

**English:**
Following Eqs. (1) and (3) as described in Section 4.2.1, we fuse the visual embedding and the 2D positional embedding to obtain a multi-modal representation $U_{O_{m}}$ for each graphical page object $O_{m}$ in a similar manner.

**Chinese:**
[cite_start]沿用 4.2.1 节中描述的公式 (1) 和 (3)，我们以类似的方式融合视觉嵌入和 2D 位置嵌入，从而获得每个图形页面对象 $O_{m}$ 的多模态表示 $U_{O_{m}}$ [cite: 435]。

**English:**
For each detected text region page object $O_{n}$ consisting of text-lines $[t_{n_{1}},t_{n_{2}},...,t_{n_{k}}]$, we propose an attention fusion model to integrate the features of text-lines $[F_{t_{n_{1}}},F_{t_{n_{2}}},...,F_{t_{n_{k}}}]$ produced by Eq. (5), thereby forming a multi-modal representation $U_{O_{n}}$ for this text region as follows:

**Chinese:**
[cite_start]对于每个由文本行 $[t_{n_{1}},t_{n_{2}},...,t_{n_{k}}]$ 组成的被检测文本区域页面对象 $O_{n}$，我们提出了一种注意力融合模型，用于整合由公式 (5) 生成的文本行特征 $[F_{t_{n_{1}}},F_{t_{n_{2}}},...,F_{t_{n_{k}}}]$，从而形成该文本区域的多模态表示 $U_{O_{n}}$，具体如下 [cite: 436, 437]：

$$
\alpha_{t_{n_{j}}}=FC_{1}(tanh(FC_{2}(F_{t_{n_{j}}}) )), \quad (10)
$$

$$
w_{t_{n_{j}}}=\frac{exp~\alpha_{t_{n_{j}}}}{\sum_{j}exp~\alpha_{t_{n_{j}}}} \quad (11)
$$

$$
U_{O_{n}}=\sum_{j}w_{t_{n_{j}}}F_{t_{n_{j}}} \quad (12)
$$

**English:**
where both $FC_{1}$ and $FC_{2}$ are single fully-connected layers with 1,024 and 1 nodes, respectively. Furthermore, for each page object, we derive a region type embedding for each page object as follows:

**Chinese:**
[cite_start]其中 $FC_{1}$ 和 $FC_{2}$ 分别是拥有 1024 个节点和 1 个节点的单层全连接层。此外，对于每个页面对象，我们按如下方式导出其区域类型嵌入 [cite: 442, 443]：

$$
R_{O_{i}}=LN(ReLU(FC(Embedding(r_{O_{i}})))), \quad (13)
$$

**English:**
where Embedding is an embedding layer with 1,024 hidden dimension and $r_{O_{i}}$ is the logical role of the page object $O_{i}$. Lastly, we concatenate each page object's multi-modal representation $U_{O}$ and region type embedding $R_{O}$ to obtain its final representation $\hat{U}_{O}$ as follows:

**Chinese:**
[cite_start]其中 Embedding 是一个隐藏维度为 1024 的嵌入层，$r_{O_{i}}$ 是页面对象 $O_{i}$ 的逻辑角色。最后，我们将每个页面对象的多模态表示 $U_{O}$ 与区域类型嵌入 $R_{O}$ 进行拼接，以获得其最终表示 $\hat{U}_{O}$，如下所示 [cite: 446, 448]：

$$
\hat{U}_{O_{i}}=FC(Concat(U_{O_{i}},R_{O_{i}})), \quad (14)
$$

**English:**
where FC is a fully-connected layer with 1,024 nodes.

**Chinese:**
[cite_start]其中 FC 是一个拥有 1024 个节点的全连接层 [cite: 450]。

---

### 4.3.2. Multi-modal Feature Enhancement Module (多模态特征增强模块)

**English:**
As illustrated in Fig. 6, we adopt a similar approach to previous multi-modal feature enhancement module in the Group stage. In this case, we utilize a three-layer Transformer encoder to further improve the multi-modal representations of page objects by modeling their interactions using a self-attention mechanism.

**Chinese:**
[cite_start]如图 6 所示，我们采用与此前分组阶段（Detect 阶段）中的多模态特征增强模块类似的方法。在这种情况下，我们利用一个三层 Transformer 编码器，通过自注意力机制对页面对象的交互进行建模，从而进一步改进其多模态表示 [cite: 453, 454]。

**English:**
Each page object is treated as a token of the Transformer encoder, and its multi-modal representation serves as the input embedding:

**Chinese:**
[cite_start]每个页面对象被视为 Transformer 编码器的一个 token，其多模态表示作为输入嵌入 [cite: 455]：

$$
F_{O}=TransformerEncoder(\hat{U}_{O}), \quad (15)
$$

**English:**
where $\hat{U}_{O}=[\hat{U}_{O_{1}},\hat{U}_{O_{2}},...,\hat{U}_{O_{n}}]$ and $F_{O}=[F_{O_{1}},F_{O_{2}},...,F_{O_{n}}]$ represent the input and output embeddings of the Transformer encoder, and n is the number of the input page objects. The hyperparameters of the transformer encoder are consistent with those in the Detect module, except for the layer number.

**Chinese:**
[cite_start]其中 $\hat{U}_{O}=[\hat{U}_{O_{1}},\hat{U}_{O_{2}},...,\hat{U}_{O_{n}}]$ 和 $F_{O}=[F_{O_{1}},F_{O_{2}},...,F_{O_{n}}]$ 分别代表 Transformer 编码器的输入和输出嵌入，n 是输入页面对象的数量。除层数外，Transformer 编码器的超参数与检测模块中的保持一致 [cite: 480, 481]。

---

### 4.3.3. Inter-region Reading Order Relation Prediction Head (区域间阅读顺序关系预测头)

**English:**
Owing to the similarity between the inter-region reading order task of the Order module and the intra-region reading order task of the Detect module, we employ an identical structure for the inter-region reading order relation prediction head in both modules. Further details about this head can be found in Section 4.2.3.

**Chinese:**
[cite_start]由于排序模块的区域间阅读顺序任务与检测模块的区域内阅读顺序任务具有相似性，我们在两个模块中为区域间阅读顺序关系预测头采用了相同的结构。关于该预测头的更多细节可见 4.2.3 节 [cite: 483, 484]。

---

### 4.3.4. Inter-region Reading Order Relation Classification Head (区域间阅读顺序关系分类头)

**English:**
We employ a multi-class classifier to compute the probability distribution across various classes in order to determine the relation type between page object $O_{i}$ and page object $O_{j}$. It works as follows:

**Chinese:**
[cite_start]我们采用一个多类别分类器来计算各个类别的概率分布，以确定页面对象 $O_{i}$ 和页面对象 $O_{j}$ 之间的关系类型。其工作原理如下 [cite: 486]：

$$
p_{ij}=BiLinear(FC_{q}(F_{O_{i}}),FC_{k}(F_{O_{j}})), \quad (16)
$$

$$
c_{ij}=argmax(p_{ij}) \quad (17)
$$

**English:**
where both $FC_{q}$ and $FC_{k}$ represent single fully-connected layers with 2,048 nodes, which are used to map $F_{O_{i}}$ and $F_{O_{j}}$ into distinct feature spaces; BiLinear signifies the bilinear classifier; and argmax refers to identifying the index $c_{ij}$ of the maximum value within the given probability distribution $p_{ij}$ as the predicted relation type.

**Chinese:**
[cite_start]其中 $FC_{q}$ 和 $FC_{k}$ 均表示拥有 2048 个节点的单层全连接层，用于将 $F_{O_{i}}$ 和 $F_{O_{j}}$ 映射到不同的特征空间；BiLinear 表示双线性分类器；argmax 指的是将给定概率分布 $p_{ij}$ 中最大值的索引 $c_{ij}$ 识别为预测的关系类型 [cite: 489, 490]。


### 4.4. Construct Module (构建模块)

**English:**
[cite_start]Given the detected section headings $[sec_{1},sec_{2},...,sec_{k-1},sec_{k}]$ arranged according to the predicted reading order sequence for document D, the goal of the Construct module is to generate a tree structure representing the hierarchical table of contents[cite: 527].

**Chinese:**
[cite_start]给定根据文档 D 的预测阅读顺序排列的已检测章节标题 $[sec_{1},sec_{2},...,sec_{k-1},sec_{k}]$，构建（Construct）模块的目标是生成一个代表层次化目录的树状结构 [cite: 527]。

---

**English:**
[cite_start]As illustrated in Fig. 7, we extract the multi-modal representation $F_{S}$ of each section heading $sec_{i}$ from all page objects' multi-modal representation $F_{O}$ based on the logical role[cite: 528]. [cite_start]Subsequently, we input all section headings' representation $U_{S}=[U_{S_{1}},U_{S_{2}},...,U_{S_{k}}]$ into a transformer encoder to further enhance the representations[cite: 529].

**Chinese:**
[cite_start]如图 7 所示，我们根据逻辑角色，从所有页面对象的多模态表示 $F_{O}$ 中提取每个章节标题 $sec_{i}$ 的多模态表示 $F_{S}$ [cite: 528][cite_start]。 随后，我们将所有章节标题的表示 $U_{S}=[U_{S_{1}},U_{S_{2}},...,U_{S_{k}}]$ 输入到一个 Transformer 编码器中，以进一步增强这些表示 [cite: 529]。

---

**English:**
[cite_start]However, unlike the transformer encoder employed in the Detect module and the Order module, both of which are order-agnostic, the input sequence $U_{S}$ has the correct reading order predicted by the Order module, allowing us to add a positional encoding to convey the reading order information[cite: 530].

**Chinese:**
[cite_start]然而，与检测（Detect）模块和排序（Order）模块中使用的对顺序不敏感的 Transformer 编码器不同，此处输入序列 $U_{S}$ 具有由排序模块预测的正确阅读顺序，这允许我们添加位置编码来传递阅读顺序信息 [cite: 530]。

---

**English:**
[cite_start]To incorporate the relative position in the reading order sequence and accommodate a larger scale of page numbers in the document, we utilize an efficient positional encoding method called Rotary Positional Embedding (ROPE)[cite: 531]. [cite_start]ROPE encodes the absolute position using a rotation matrix and simultaneously includes the explicit relative position dependency in the self-attention formulation[cite: 532].

**Chinese:**
[cite_start]为了整合阅读顺序序列中的相对位置并适应文档中更大范围的页码，我们使用了一种称为旋转位置编码（Rotary Positional Embedding, ROPE） 的高效位置编码方法 [cite: 531][cite_start]。 ROPE 使用旋转矩阵对绝对位置进行编码，并在自注意力公式中同时包含显式的相对位置依赖关系 [cite: 532]。

---

**English:**
[cite_start]Following the Multi-modal Feature Enhancement Module, we generate the enhanced representations $F_{S}=[F_{S_{1}},F_{S_{2}},...,F_{S_{k}}]$ for section headings[cite: 533]. [cite_start]Finally, we introduce a tree-aware TOC relation prediction head to predict the TOC relationships among these section headings[cite: 534]. [cite_start]The specially designed relation prediction head is illustrated in Fig. 8[cite: 535].

**Chinese:**
[cite_start]在多模态特征增强模块之后，我们生成章节标题的增强表示 $F_{S}=[F_{S_{1}},F_{S_{2}},...,F_{S_{k}}]$ [cite: 533][cite_start]。 最后，我们引入了一个感知树结构的目录（TOC）关系预测头，以预测这些章节标题之间的 TOC 关系 [cite: 534][cite_start]。 这个专门设计的关系预测头如图 8 所示 [cite: 535]。

---

### 4.4.1. TOC Relation Prediction Head (目录关系预测头)

**English:**
[cite_start]During the generation of the ordered tree for Table of Contents, solely relying on the relationship features between child and parent nodes has proven to be insufficient[cite: 537]. [cite_start]Some prior studies have already observed that incorporating information from sibling nodes can lead to an improved generation of the TOC[cite: 538, 540].

**Chinese:**
[cite_start]在生成目录的有序树的过程中，仅依赖子节点和父节点之间的关系特征已被证明是不够的 [cite: 537][cite_start]。 一些先前的研究已经观察到，结合兄弟节点的信息可以改善目录的生成 [cite: 538, 540]。

---

**English:**
[cite_start]Inspired by these works, we propose two types of TOC relationships between section heads to further enhance the TOC generation process: parent-child relationships and sibling relationships[cite: 541]. [cite_start]The parent-child relationship is relatively straightforward: when a section heading $sec_{i}$ serves as the parent node for another section heading $sec_{j}$ within the TOC tree structure, we define a parent-child relationship $(sec_{j}\rightarrow sec_{i})$ that points from $sec_{j}$ to $sec_{i}$[cite: 542].

**Chinese:**
[cite_start]受这些工作的启发，我们提出了章节标题之间的两种 TOC 关系类型，以进一步增强 TOC 生成过程：父子关系和兄弟关系 [cite: 541][cite_start]。 父子关系相对简单：当章节标题 $sec_{i}$ 在 TOC 树结构中作为另一个章节标题 $sec_{j}$ 的父节点时，我们定义一个从 $sec_{j}$ 指向 $sec_{i}$ 的父子关系 $(sec_{j}\rightarrow sec_{i})$ [cite: 542]。

---

**English:**
[cite_start]Sibling relationships in a TOC tree are established as follows: if section heading $sec_{i}$ acts as the left sibling of section heading $sec_{j}$ then a sibling relationship $(sec_{j}\rightarrow sec_{i})$ is present[cite: 543]. [cite_start]In cases where a section heading lacks a parent node or left sibling node, its parent-child or sibling relationship is defined as pointing to itself[cite: 544]. [cite_start]This approach aims to provide a more comprehensive representation of the relationships among section heads, ultimately leading to a more accurate and robust TOC generation[cite: 545].

**Chinese:**
[cite_start]TOC 树中的兄弟关系建立如下：如果章节标题 $sec_{i}$ 是章节标题 $sec_{j}$ 的左兄弟节点，则存在兄弟关系 $(sec_{j}\rightarrow sec_{i})$ [cite: 543][cite_start]。 如果一个章节标题没有父节点或左兄弟节点，其父子关系或兄弟关系被定义为指向其自身 [cite: 544][cite_start]。 这种方法旨在提供更全面的章节标题关系表示，最终实现更准确和鲁棒的 TOC 生成 [cite: 545]。

---

**English:**
[cite_start]As illustrated in Fig. 8, our proposed TOC Relation Prediction Head comprises two distinct relation prediction heads for the parent-child and sibling relationships, respectively[cite: 546]. [cite_start]Both relation prediction heads in our proposed module employ the same network structure[cite: 547]. [cite_start]To elaborate, we use the relation prediction head for the parent-child relationship as an example[cite: 548].

**Chinese:**
[cite_start]如图 8 所示，我们提出的 TOC 关系预测头包含两个分别用于父子关系和兄弟关系的独立关系预测头 [cite: 546][cite_start]。 我们模块中提出的这两个关系预测头采用了相同的网络结构 [cite: 547][cite_start]。 详细来说，我们以父子关系的关系预测头为例 [cite: 548]。

---

**English:**
[cite_start]Specifically, we implement a multi-class (k-class) classifier to compute a score $s_{ij}^{p}$, which estimates the likelihood of $sec_{j}$ being the parent node of $sec_{i}$[cite: 549]. The calculation is as follows:
$$f_{ij}=FC_{q}(F_{S_{i}})\circ FC_{k}(F_{S_{j}})$$
$$s_{ij}^{p}=\frac{exp(f_{ij})}{\sum_{j}exp(f_{ij})}$$
where each of $FC_{q}$ and $FC_{k}$ represents a single fully-connected layer with 2,048 nodes to map $F_{S_{i}}$ and $F_{S_{j}}$ into distinct feature spaces; [cite_start]$\circ$ denotes the dot product operation [cite: 551-554].

**Chinese:**
[cite_start]具体而言，我们实现了一个多类（k-class）分类器来计算分数 $s_{ij}^{p}$，该分数估计 $sec_{j}$ 作为 $sec_{i}$ 父节点的可能性 [cite: 549]。 计算如下：
$$f_{ij}=FC_{q}(F_{S_{i}})\circ FC_{k}(F_{S_{j}})$$
$$s_{ij}^{p}=\frac{exp(f_{ij})}{\sum_{j}exp(f_{ij})}$$
[cite_start]其中，$FC_{q}$ 和 $FC_{k}$ 分别表示具有 2,048 个节点的单层全连接层，用于将 $F_{S_{i}}$ 和 $F_{S_{j}}$ 映射到不同的特征空间；$\circ$ 表示点积运算 [cite: 551-554]。

---

**English:**
[cite_start]Similarly, we can obtain the score $s_{ij}^{s}$ to estimate the likelihood of $sec_{j}$ being the defined sibling node of $sec_{i}$[cite: 554]. [cite_start]This unified network structure allows for efficient and effective prediction of relationships between section heads, contributing to the overall TOC generation process[cite: 554].

**Chinese:**
[cite_start]同样地，我们可以获得分数 $s_{ij}^{s}$ 来估计 $sec_{j}$ 作为 $sec_{i}$ 定义的兄弟节点的可能性 [cite: 554][cite_start]。 这种统一的网络结构允许高效且有效地预测章节标题之间的关系，从而有助于整体的 TOC 生成过程 [cite: 554]。

---

**English:**
[cite_start]In a manner similar to the previously proposed reading order relation prediction head in Section 4.2.3, we treat relation prediction as a dependency parsing task and employ a softmax cross-entropy loss instead of the standard binary cross-entropy loss during the training phase[cite: 555].

**Chinese:**
[cite_start]与第 4.2.3 节中先前提出的阅读顺序关系预测头类似，我们将关系预测视为依存句法分析任务，并在训练阶段采用 Softmax 交叉熵损失代替标准的二元交叉熵损失 [cite: 555]。

---

**English:**
[cite_start]During the testing phase, we utilize serial decoding to integrate the outputs of the two relation prediction heads and introduce a tree structure constraint to enhance the final prediction results[cite: 556]. [cite_start]Specifically, assuming that $[sec_{1},sec_{2},...,sec_{k}]$ has been sorted according to the predicted reading order, we initialize a tree T containing only one root node, ROOT[cite: 557].

**Chinese:**
[cite_start]在测试阶段，我们利用串行解码来整合两个关系预测头的输出，并引入树结构约束以增强最终的预测结果 [cite: 556][cite_start]。 具体而言，假设 $[sec_{1},sec_{2},...,sec_{k}]$ 已经根据预测的阅读顺序进行了排序，我们初始化一棵仅包含一个根节点 ROOT 的树 T [cite: 557]。

---

**English:**
[cite_start]Subsequently, we devise a tree insertion algorithm, as detailed in Algorithm 1, to insert each section heading in order, ultimately generating a complete table of contents tree[cite: 558]. [cite_start]This approach ensures that the predicted relationships between section headings are consistent with the hierarchical tree structure, resulting in a more accurate and coherent TOC[cite: 559].

**Chinese:**
[cite_start]随后，我们设计了一种树插入算法（如算法 1 详述），按顺序插入每个章节标题，最终生成完整的目录树 [cite: 558][cite_start]。 这种方法确保了预测的章节标题之间的关系与层次树结构保持一致，从而产生更准确、更连贯的目录 [cite: 559]。