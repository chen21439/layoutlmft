# 4.3. Order Module (排序模块)

**English:**
The Order module focuses on determining the reading sequence of graphical page objects and text regions identified by the Detect module within document D. Similar to the bottom-up text region detection model employed in the Detect module, we also utilize our proposed multi-modal, transformer-based relation prediction model to predict the inter-region reading order relationships among the recognized page objects.

**Chinese:**
[cite_start]排序模块专注于确定检测模块在文档 D 中识别出的图形页面对象和文本区域的阅读顺序。与检测模块中采用的自底向上文本区域检测模型类似，我们也利用我们提出的多模态、基于 Transformer 的关系预测模型来预测已识别页面对象之间的区域间阅读顺序关系 [cite: 429]。

**English:**
The Order module processes the detected page objects as input and employs an attention-based approach to integrate the features of text-lines belonging to the same text region, thereby achieving a more efficient feature representation of the text region. Furthermore, we define two categories of inter-region reading order relationships: (1) Text region reading order relationships between main body text regions, (2) Graphical region reading order relationships between captions/footnotes and graphical page objects such as tables and figures.

**Chinese:**
[cite_start]排序模块将检测到的页面对象作为输入，并采用基于注意力的方法来整合属于同一文本区域的文本行的特征，从而实现对文本区域更高效的特征表示。此外，我们将区域间阅读顺序关系定义为两类：（1）正文文本区域之间的文本区域阅读顺序关系；（2）说明文字/脚注与图形页面对象（如表格和插图）之间的图形区域阅读顺序关系 [cite: 430, 431]。

**English:**
Consequently, we incorporate an additional inter-region reading order relation classification head to predict relation types. A detailed illustration of the Order module can be found in Fig. 6.

**Chinese:**
[cite_start]因此，我们引入了一个额外的区域间阅读顺序关系分类头来预测关系类型。排序模块的详细示意图见图 6 [cite: 432, 433]。

---

### 4.3.1. Multi-modal Feature Extraction Module (多模态特征提取模块)

**English:**
Following Eqs. (1) and (3) as described in Section 4.2.1, we fuse the visual embedding and the 2D positional embedding to obtain a multi-modal representation $U_{O_{m}}$ for each graphical page object $O_{m}$ in a similar manner.

**Chinese:**
[cite_start]沿用 4.2.1 节中描述的公式 (1) 和 (3)，我们以类似的方式融合视觉嵌入和 2D 位置嵌入，从而获得每个图形页面对象 $O_{m}$ 的多模态表示 $U_{O_{m}}$ [cite: 435]。

**English:**
For each detected text region page object $O_{n}$ consisting of text-lines $[t_{n_{1}},t_{n_{2}},...,t_{n_{k}}]$, we propose an attention fusion model to integrate the features of text-lines $[F_{t_{n_{1}}},F_{t_{n_{2}}},...,F_{t_{n_{k}}}]$ produced by Eq. (5), thereby forming a multi-modal representation $U_{O_{n}}$ for this text region as follows:

**Chinese:**
[cite_start]对于每个由文本行 $[t_{n_{1}},t_{n_{2}},...,t_{n_{k}}]$ 组成的被检测文本区域页面对象 $O_{n}$，我们提出了一种注意力融合模型，用于整合由公式 (5) 生成的文本行特征 $[F_{t_{n_{1}}},F_{t_{n_{2}}},...,F_{t_{n_{k}}}]$，从而形成该文本区域的多模态表示 $U_{O_{n}}$，具体如下 [cite: 436, 437]：

$$
\alpha_{t_{n_{j}}}=FC_{1}(tanh(FC_{2}(F_{t_{n_{j}}}) )), \quad (10)
$$

$$
w_{t_{n_{j}}}=\frac{exp~\alpha_{t_{n_{j}}}}{\sum_{j}exp~\alpha_{t_{n_{j}}}} \quad (11)
$$

$$
U_{O_{n}}=\sum_{j}w_{t_{n_{j}}}F_{t_{n_{j}}} \quad (12)
$$

**English:**
where both $FC_{1}$ and $FC_{2}$ are single fully-connected layers with 1,024 and 1 nodes, respectively. Furthermore, for each page object, we derive a region type embedding for each page object as follows:

**Chinese:**
[cite_start]其中 $FC_{1}$ 和 $FC_{2}$ 分别是拥有 1024 个节点和 1 个节点的单层全连接层。此外，对于每个页面对象，我们按如下方式导出其区域类型嵌入 [cite: 442, 443]：

$$
R_{O_{i}}=LN(ReLU(FC(Embedding(r_{O_{i}})))), \quad (13)
$$

**English:**
where Embedding is an embedding layer with 1,024 hidden dimension and $r_{O_{i}}$ is the logical role of the page object $O_{i}$. Lastly, we concatenate each page object's multi-modal representation $U_{O}$ and region type embedding $R_{O}$ to obtain its final representation $\hat{U}_{O}$ as follows:

**Chinese:**
[cite_start]其中 Embedding 是一个隐藏维度为 1024 的嵌入层，$r_{O_{i}}$ 是页面对象 $O_{i}$ 的逻辑角色。最后，我们将每个页面对象的多模态表示 $U_{O}$ 与区域类型嵌入 $R_{O}$ 进行拼接，以获得其最终表示 $\hat{U}_{O}$，如下所示 [cite: 446, 448]：

$$
\hat{U}_{O_{i}}=FC(Concat(U_{O_{i}},R_{O_{i}})), \quad (14)
$$

**English:**
where FC is a fully-connected layer with 1,024 nodes.

**Chinese:**
[cite_start]其中 FC 是一个拥有 1024 个节点的全连接层 [cite: 450]。

---

### 4.3.2. Multi-modal Feature Enhancement Module (多模态特征增强模块)

**English:**
As illustrated in Fig. 6, we adopt a similar approach to previous multi-modal feature enhancement module in the Group stage. In this case, we utilize a three-layer Transformer encoder to further improve the multi-modal representations of page objects by modeling their interactions using a self-attention mechanism.

**Chinese:**
[cite_start]如图 6 所示，我们采用与此前分组阶段（Detect 阶段）中的多模态特征增强模块类似的方法。在这种情况下，我们利用一个三层 Transformer 编码器，通过自注意力机制对页面对象的交互进行建模，从而进一步改进其多模态表示 [cite: 453, 454]。

**English:**
Each page object is treated as a token of the Transformer encoder, and its multi-modal representation serves as the input embedding:

**Chinese:**
[cite_start]每个页面对象被视为 Transformer 编码器的一个 token，其多模态表示作为输入嵌入 [cite: 455]：

$$
F_{O}=TransformerEncoder(\hat{U}_{O}), \quad (15)
$$

**English:**
where $\hat{U}_{O}=[\hat{U}_{O_{1}},\hat{U}_{O_{2}},...,\hat{U}_{O_{n}}]$ and $F_{O}=[F_{O_{1}},F_{O_{2}},...,F_{O_{n}}]$ represent the input and output embeddings of the Transformer encoder, and n is the number of the input page objects. The hyperparameters of the transformer encoder are consistent with those in the Detect module, except for the layer number.

**Chinese:**
[cite_start]其中 $\hat{U}_{O}=[\hat{U}_{O_{1}},\hat{U}_{O_{2}},...,\hat{U}_{O_{n}}]$ 和 $F_{O}=[F_{O_{1}},F_{O_{2}},...,F_{O_{n}}]$ 分别代表 Transformer 编码器的输入和输出嵌入，n 是输入页面对象的数量。除层数外，Transformer 编码器的超参数与检测模块中的保持一致 [cite: 480, 481]。

---

### 4.3.3. Inter-region Reading Order Relation Prediction Head (区域间阅读顺序关系预测头)

**English:**
Owing to the similarity between the inter-region reading order task of the Order module and the intra-region reading order task of the Detect module, we employ an identical structure for the inter-region reading order relation prediction head in both modules. Further details about this head can be found in Section 4.2.3.

**Chinese:**
[cite_start]由于排序模块的区域间阅读顺序任务与检测模块的区域内阅读顺序任务具有相似性，我们在两个模块中为区域间阅读顺序关系预测头采用了相同的结构。关于该预测头的更多细节可见 4.2.3 节 [cite: 483, 484]。

---

### 4.3.4. Inter-region Reading Order Relation Classification Head (区域间阅读顺序关系分类头)

**English:**
We employ a multi-class classifier to compute the probability distribution across various classes in order to determine the relation type between page object $O_{i}$ and page object $O_{j}$. It works as follows:

**Chinese:**
[cite_start]我们采用一个多类别分类器来计算各个类别的概率分布，以确定页面对象 $O_{i}$ 和页面对象 $O_{j}$ 之间的关系类型。其工作原理如下 [cite: 486]：

$$
p_{ij}=BiLinear(FC_{q}(F_{O_{i}}),FC_{k}(F_{O_{j}})), \quad (16)
$$

$$
c_{ij}=argmax(p_{ij}) \quad (17)
$$

**English:**
where both $FC_{q}$ and $FC_{k}$ represent single fully-connected layers with 2,048 nodes, which are used to map $F_{O_{i}}$ and $F_{O_{j}}$ into distinct feature spaces; BiLinear signifies the bilinear classifier; and argmax refers to identifying the index $c_{ij}$ of the maximum value within the given probability distribution $p_{ij}$ as the predicted relation type.

**Chinese:**
[cite_start]其中 $FC_{q}$ 和 $FC_{k}$ 均表示拥有 2048 个节点的单层全连接层，用于将 $F_{O_{i}}$ 和 $F_{O_{j}}$ 映射到不同的特征空间；BiLinear 表示双线性分类器；argmax 指的是将给定概率分布 $p_{ij}$ 中最大值的索引 $c_{ij}$ 识别为预测的关系类型 [cite: 489, 490]。