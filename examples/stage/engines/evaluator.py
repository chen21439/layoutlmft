#!/usr/bin/env python
# coding=utf-8
"""
Evaluator - ç»Ÿä¸€è¯„ä¼°æ¥å£

æ”¯æŒé¡µé¢çº§åˆ«å’Œæ–‡æ¡£çº§åˆ«çš„è¯„ä¼°ï¼Œä½¿ç”¨ Batch æŠ½è±¡å±‚éšè—å·®å¼‚ã€‚

è®¾è®¡åŸåˆ™ï¼š
- ä½¿ç”¨ Predictor è¿›è¡Œæ¨ç†
- ä» Sample ä¸­æå– GT
- è®¡ç®—æŒ‡æ ‡å¹¶è¿”å› EvaluationOutput
"""

import torch
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Any, Tuple
from collections import defaultdict
from tqdm import tqdm

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from data.batch import Sample, BatchBase, wrap_batch
from .predictor import Predictor, PredictionOutput

# å¯¼å…¥ TEDS è®¡ç®—å‡½æ•°
try:
    from util.hrdoc_eval import compute_teds_score
    TEDS_AVAILABLE = True
except ImportError:
    TEDS_AVAILABLE = False


# æ ‡ç­¾æ˜ å°„ï¼ˆä» layoutlmft.data.labels å¯¼å…¥æˆ–å®šä¹‰ï¼‰
try:
    from layoutlmft.data.labels import LABEL_LIST, LABEL2ID, ID2LABEL
except ImportError:
    LABEL_LIST = [
        "other", "title", "section", "list", "table", "figure",
        "caption", "header", "footer", "equation", "abstract",
        "reference", "paragraph", "toc"
    ]
    LABEL2ID = {label: i for i, label in enumerate(LABEL_LIST)}
    ID2LABEL = {i: label for i, label in enumerate(LABEL_LIST)}

# å…³ç³»æ˜ å°„
RELATION_LABELS = {"connect": 0, "contain": 1, "equality": 2}
ID2RELATION = {v: k for k, v in RELATION_LABELS.items()}


@dataclass
class EvaluationOutput:
    """è¯„ä¼°ç»“æœ"""
    # Stage 1: åˆ†ç±»æŒ‡æ ‡
    line_accuracy: float = 0.0
    line_macro_f1: float = 0.0
    line_micro_f1: float = 0.0

    # Stage 3: Parent å‡†ç¡®ç‡
    parent_accuracy: float = 0.0

    # Stage 4: Relation æŒ‡æ ‡
    relation_accuracy: float = 0.0
    relation_macro_f1: float = 0.0
    relation_micro_f1: float = 0.0

    # TEDS æŒ‡æ ‡
    teds_score: Optional[float] = None

    # ç»Ÿè®¡ä¿¡æ¯
    num_samples: int = 0
    num_lines: int = 0
    num_parent_pairs: int = 0
    num_relation_pairs: int = 0

    # è¯¦ç»†æŒ‡æ ‡ï¼ˆå¯é€‰ï¼‰
    per_class_f1: Optional[Dict[str, float]] = None
    per_relation_f1: Optional[Dict[str, float]] = None
    confusion_matrix: Optional[Any] = None


class Evaluator:
    """
    ç»Ÿä¸€è¯„ä¼°å™¨

    ä½¿ç”¨æ–¹å¼ï¼š
        evaluator = Evaluator(model, device)
        output = evaluator.evaluate(dataloader)
    """

    def __init__(
        self,
        model: torch.nn.Module,
        device: torch.device = None,
        id2label: Dict[int, str] = None,
    ):
        """
        Args:
            model: JointModel
            device: è®¡ç®—è®¾å¤‡
            id2label: ç±»åˆ« ID åˆ°åç§°çš„æ˜ å°„
        """
        self.predictor = Predictor(model, device)
        self.device = device or next(model.parameters()).device
        self.id2label = id2label or ID2LABEL

    def evaluate(
        self,
        dataloader,
        compute_teds: bool = False,
        verbose: bool = True,
        debug: bool = False,
        save_predictions: bool = False,
        output_dir: str = None,
    ) -> EvaluationOutput:
        """
        è¯„ä¼°æ•´ä¸ªæ•°æ®é›†

        Args:
            dataloader: DataLoaderï¼Œè¿”å› raw batch dict
            compute_teds: æ˜¯å¦è®¡ç®— TEDSï¼ˆè¾ƒæ…¢ï¼‰
            verbose: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡
            debug: æ˜¯å¦æ‰“å°è°ƒè¯•ä¿¡æ¯
            save_predictions: æ˜¯å¦ä¿å­˜é¢„æµ‹ç»“æœåˆ°æ–‡ä»¶
            output_dir: é¢„æµ‹ç»“æœè¾“å‡ºç›®å½•

        Returns:
            EvaluationOutput: è¯„ä¼°ç»“æœ
        """
        self.predictor.model.eval()

        # æ”¶é›†æ‰€æœ‰é¢„æµ‹å’Œ GT
        all_gt_classes = []
        all_pred_classes = []
        all_gt_parents = []
        all_pred_parents = []
        all_gt_relations = []
        all_pred_relations = []

        # æ”¶é›†é¢„æµ‹ç»“æœç”¨äºä¿å­˜
        all_predictions = []

        # æ”¶é›†ç”¨äº TEDS è®¡ç®—çš„æ–‡æ¡£çº§æ•°æ®
        teds_gt_docs = []
        teds_pred_docs = []

        num_samples = 0

        # è°ƒè¯•ç»Ÿè®¡
        debug_parent_skipped_padding = 0
        debug_parent_skipped_invalid = 0
        debug_parent_total = 0
        debug_first_samples = []
        self._parent_class_stats = []  # é‡ç½® parent ç±»åˆ«ç»Ÿè®¡
        self._doc_json_paths = {}  # æ–‡æ¡£å -> json_path æ˜ å°„

        iterator = tqdm(dataloader, desc="Evaluating") if verbose else dataloader

        with torch.no_grad():
            for raw_batch in iterator:
                # åŒ…è£…ä¸º Batch æŠ½è±¡
                batch = wrap_batch(raw_batch)
                batch = batch.to(self.device)

                for sample in batch:
                    num_samples += 1

                    # ä¿å­˜ json_path æ˜ å°„
                    if sample.document_name and sample.json_path:
                        self._doc_json_paths[sample.document_name] = sample.json_path

                    # æå– GT
                    gt = self._extract_gt(sample)

                    # é¢„æµ‹
                    pred = self.predictor.predict(sample)

                    # æ”¶é›†é¢„æµ‹ç»“æœç”¨äºä¿å­˜ï¼ˆæŒ‰æ–‡æ¡£åˆ†ç»„ï¼ŒåŒæ—¶ä¿å­˜ GT å’Œé¢„æµ‹ï¼‰
                    if save_predictions:
                        doc_name = sample.document_name or f"doc_{num_samples}"
                        sorted_line_ids = sorted(pred.line_classes.keys())
                        doc_lines = []
                        for idx, line_id in enumerate(sorted_line_ids):
                            # é¢„æµ‹ç»“æœ
                            pred_class = pred.line_classes.get(line_id, 0)
                            pred_parent = pred.line_parents[idx] if idx < len(pred.line_parents) else -1
                            pred_relation = pred.line_relations[idx] if idx < len(pred.line_relations) else 0
                            # GT ç»“æœ
                            gt_class = gt["classes"].get(line_id, -1)
                            gt_parent = gt["parents"][idx] if idx < len(gt["parents"]) else -1
                            gt_relation = gt["relations"][idx] if idx < len(gt["relations"]) else -1
                            doc_lines.append({
                                "line_id": line_id,
                                "gt_class": self.id2label.get(gt_class, f"cls_{gt_class}"),
                                "pred_class": self.id2label.get(pred_class, f"cls_{pred_class}"),
                                "gt_parent_id": gt_parent,
                                "pred_parent_id": pred_parent,
                                "gt_relation": ID2RELATION.get(gt_relation, f"rel_{gt_relation}") if gt_relation >= 0 else "N/A",
                                "pred_relation": ID2RELATION.get(pred_relation, f"rel_{pred_relation}"),
                            })
                        all_predictions.append({
                            "document_name": doc_name,
                            "lines": doc_lines,
                        })

                    # æ”¶é›†åˆ†ç±»ç»“æœ
                    for line_id, gt_class in gt["classes"].items():
                        pred_class = pred.line_classes.get(line_id, 0)
                        all_gt_classes.append(gt_class)
                        all_pred_classes.append(pred_class)

                    # æ”¶é›† Parent ç»“æœ
                    # æ³¨æ„ï¼šgt_parent = -1 è¡¨ç¤º ROOTï¼Œä¹Ÿæ˜¯æœ‰æ•ˆç›®æ ‡
                    # gt_parent = -100 è¡¨ç¤º paddingï¼Œåº”è¯¥è·³è¿‡
                    gt_line_ids = gt.get("line_ids", list(range(len(gt["parents"]))))

                    # è°ƒè¯•ï¼šæ‰“å°å‰å‡ ä¸ªæ ·æœ¬çš„å¯¹é½ä¿¡æ¯
                    if debug and num_samples <= 2:
                        print(f"\n[Parent Debug] Sample {num_samples}:")
                        print(f"  gt['parents'][:10] = {gt['parents'][:10]}")
                        print(f"  gt['line_ids'][:10] = {gt['line_ids'][:10]}")
                        print(f"  pred.line_parents[:10] = {pred.line_parents[:10]}")
                        print(f"  pred.line_ids[:10] = {pred.line_ids[:10]}")
                        print(f"  len(gt['parents'])={len(gt['parents'])}, len(pred.line_parents)={len(pred.line_parents)}")

                    for idx, (gt_parent, pred_parent) in enumerate(zip(
                        gt["parents"], pred.line_parents
                    )):
                        debug_parent_total += 1
                        if gt_parent == -100:
                            debug_parent_skipped_padding += 1
                            continue
                        if idx >= len(pred.line_parents):
                            continue
                        # ä½¿ç”¨å®é™… line_id è€Œä¸æ˜¯ idx æ¥åˆ¤æ–­çˆ¶å­å…³ç³»æœ‰æ•ˆæ€§
                        # parent çš„ line_id å¿…é¡»å°äº child çš„ line_id
                        child_line_id = gt_line_ids[idx] if idx < len(gt_line_ids) else idx
                        if gt_parent >= child_line_id:
                            debug_parent_skipped_invalid += 1
                            continue
                        all_gt_parents.append(gt_parent)
                        all_pred_parents.append(pred_parent)

                        # æ”¶é›† parent ç±»åˆ«ç»Ÿè®¡ä¿¡æ¯
                        child_class = gt["classes"].get(child_line_id, -1)
                        gt_parent_line_id = gt_line_ids[gt_parent] if gt_parent >= 0 and gt_parent < len(gt_line_ids) else None
                        gt_parent_class = gt["classes"].get(gt_parent_line_id, None) if gt_parent_line_id is not None else None
                        pred_parent_line_id = gt_line_ids[pred_parent] if pred_parent >= 0 and pred_parent < len(gt_line_ids) else None
                        pred_parent_class = gt["classes"].get(pred_parent_line_id, None) if pred_parent_line_id is not None else None

                        # è·å–å®é™…çš„ line_idï¼ˆä¸æ˜¯ç´¢å¼•ï¼‰
                        child_line_id = gt_line_ids[idx] if idx < len(gt_line_ids) else idx
                        gt_parent_line_id = gt_line_ids[gt_parent] if gt_parent >= 0 and gt_parent < len(gt_line_ids) else -1
                        pred_parent_line_id_val = gt_line_ids[pred_parent] if pred_parent >= 0 and pred_parent < len(gt_line_ids) else -1

                        self._parent_class_stats.append({
                            "child_idx": idx,
                            "child_class": child_class,
                            "child_line_id": child_line_id,
                            "gt_parent": gt_parent,
                            "gt_parent_class": gt_parent_class,
                            "gt_parent_line_id": gt_parent_line_id,
                            "pred_parent": pred_parent,
                            "pred_parent_class": pred_parent_class,
                            "pred_parent_line_id": pred_parent_line_id_val,
                            "is_correct": gt_parent == pred_parent,
                            "document_name": sample.document_name,
                        })

                        # è°ƒè¯•ï¼šæ”¶é›†å‰å‡ ä¸ªæ ·æœ¬çš„è¯¦æƒ…
                        if debug and len(debug_first_samples) < 5 and num_samples <= 2:
                            debug_first_samples.append({
                                "sample": num_samples,
                                "child_idx": idx,
                                "child_line_id": child_line_id,
                                "gt_parent": gt_parent,
                                "pred_parent": pred_parent,
                                "num_lines_gt": len(gt["parents"]),
                                "num_lines_pred": len(pred.line_parents),
                            })

                    # æ”¶é›† Relation ç»“æœ
                    # æ³¨æ„ï¼šrelation åªåœ¨ parent >= 0 ä¸” parent < child_line_id æ—¶æœ‰æ•ˆ
                    for idx, (gt_rel, gt_parent, pred_rel) in enumerate(zip(
                        gt["relations"], gt["parents"], pred.line_relations
                    )):
                        if gt_parent == -100 or gt_rel == -100:
                            continue
                        if idx >= len(pred.line_relations):
                            continue
                        # ä½¿ç”¨å®é™… line_id è¿›è¡Œæ¯”è¾ƒ
                        child_line_id = gt_line_ids[idx] if idx < len(gt_line_ids) else idx
                        if gt_parent < 0 or gt_parent >= child_line_id:
                            continue
                        all_gt_relations.append(gt_rel)
                        all_pred_relations.append(pred_rel)

                    # æ”¶é›†ç”¨äº TEDS è®¡ç®—çš„æ–‡æ¡£çº§æ•°æ®
                    if compute_teds and TEDS_AVAILABLE:
                        sorted_line_ids = sorted(gt["classes"].keys())
                        gt_doc = []
                        pred_doc = []
                        for idx, line_id in enumerate(sorted_line_ids):
                            gt_class_id = gt["classes"].get(line_id, 0)
                            pred_class_id = pred.line_classes.get(line_id, 0)
                            gt_parent_idx = gt["parents"][idx] if idx < len(gt["parents"]) else -1
                            pred_parent_idx = pred.line_parents[idx] if idx < len(pred.line_parents) else -1
                            gt_rel_id = gt["relations"][idx] if idx < len(gt["relations"]) else -100
                            pred_rel_id = pred.line_relations[idx] if idx < len(pred.line_relations) else 0

                            gt_doc.append({
                                "class": self.id2label.get(gt_class_id, f"cls_{gt_class_id}"),
                                "text": f"line_{line_id}",
                                "parent_id": gt_parent_idx,
                                "relation": ID2RELATION.get(gt_rel_id, "none") if gt_rel_id >= 0 else "none",
                            })
                            pred_doc.append({
                                "class": self.id2label.get(pred_class_id, f"cls_{pred_class_id}"),
                                "text": f"line_{line_id}",
                                "parent_id": pred_parent_idx,
                                "relation": ID2RELATION.get(pred_rel_id, "none"),
                            })
                        if gt_doc and pred_doc:
                            teds_gt_docs.append(gt_doc)
                            teds_pred_docs.append(pred_doc)

        # æ‰“å°è°ƒè¯•ä¿¡æ¯
        if debug or verbose:
            # é¢„æµ‹ç±»åˆ«ç»Ÿè®¡ï¼ˆtitle/section ç­‰ï¼‰
            from collections import Counter
            pred_class_counter = Counter(all_pred_classes)
            gt_class_counter = Counter(all_gt_classes)
            print(f"\n[Evaluator Debug] Prediction class distribution:")
            for cls_id in sorted(set(pred_class_counter.keys()) | set(gt_class_counter.keys())):
                cls_name = self.id2label.get(cls_id, f"cls_{cls_id}")
                gt_cnt = gt_class_counter.get(cls_id, 0)
                pred_cnt = pred_class_counter.get(cls_id, 0)
                diff = pred_cnt - gt_cnt
                diff_str = f"+{diff}" if diff > 0 else str(diff)
                print(f"  {cls_name}: GT={gt_cnt}, Pred={pred_cnt} ({diff_str})")

            print(f"\n[Evaluator Debug] Parent: evaluated={len(all_gt_parents)}, skipped_padding={debug_parent_skipped_padding}, skipped_invalid={debug_parent_skipped_invalid}")

            # Parent æŒ‰ç±»åˆ«ç»Ÿè®¡
            if all_gt_parents and hasattr(self, '_parent_class_stats'):
                from collections import Counter
                stats = self._parent_class_stats
                print(f"[Evaluator Debug] Parent by class (child_class -> parent_class):")
                # æŒ‰ child class åˆ†ç»„ç»Ÿè®¡
                child_class_stats = defaultdict(lambda: {"correct": 0, "total": 0})
                for item in stats:
                    child_cls = item["child_class"]
                    child_class_stats[child_cls]["total"] += 1
                    if item["is_correct"]:
                        child_class_stats[child_cls]["correct"] += 1

                for child_cls in sorted(child_class_stats.keys()):
                    s = child_class_stats[child_cls]
                    cls_name = self.id2label.get(child_cls, f"cls_{child_cls}")
                    acc = 100 * s["correct"] / s["total"] if s["total"] > 0 else 0
                    print(f"  {cls_name}: {s['correct']}/{s['total']} = {acc:.1f}%")

                # æ‰“å°ä¸€äº›é”™è¯¯æ¡ˆä¾‹
                errors = [item for item in stats if not item["is_correct"]][:10]
                if errors:
                    print(f"[Evaluator Debug] Parent errors (first 10):")
                    for e in errors:
                        child_name = self.id2label.get(e["child_class"], f"cls_{e['child_class']}")
                        gt_parent_name = self.id2label.get(e["gt_parent_class"], f"cls_{e['gt_parent_class']}") if e["gt_parent_class"] is not None else "ROOT"
                        pred_parent_name = self.id2label.get(e["pred_parent_class"], f"cls_{e['pred_parent_class']}") if e["pred_parent_class"] is not None else "ROOT"
                        print(f"  child[{e['child_idx']}]={child_name}, gt_parent={e['gt_parent']}({gt_parent_name}), pred_parent={e['pred_parent']}({pred_parent_name})")

                # æŒ‰ (child_class, gt_parent_class) åˆ†ç»„ç»Ÿè®¡è¯¯åˆ¤æƒ…å†µ
                self._print_parent_confusion_matrix(stats)

                # æ‰“å° Section è¯¦ç»†ç»Ÿè®¡è¡¨æ ¼
                self._print_section_stats(stats, gt_class_counter, pred_class_counter)

            # Relation ç»Ÿè®¡
            if all_gt_relations:
                from collections import Counter
                gt_rel_counter = Counter(all_gt_relations)
                pred_rel_counter = Counter(all_pred_relations)
                # è½¬æ¢ä¸ºè‹±æ–‡åç§°
                gt_rel_named = {ID2RELATION.get(k, f"rel_{k}"): v for k, v in gt_rel_counter.items()}
                pred_rel_named = {ID2RELATION.get(k, f"rel_{k}"): v for k, v in pred_rel_counter.items()}
                print(f"[Evaluator Debug] Relation: evaluated={len(all_gt_relations)}")
                print(f"  GT:   {gt_rel_named}")
                print(f"  Pred: {pred_rel_named}")
                # è®¡ç®—æ¯ç±» Recall
                for rel_id in sorted(gt_rel_counter.keys()):
                    gt_count = gt_rel_counter[rel_id]
                    correct = sum(1 for g, p in zip(all_gt_relations, all_pred_relations) if g == rel_id and p == rel_id)
                    rel_name = ID2RELATION.get(rel_id, f"rel_{rel_id}")
                    print(f"  {rel_name}: GT={gt_count}, Correct={correct}, Recall={100*correct/gt_count:.1f}%")

        # è®¡ç®—æŒ‡æ ‡
        output = self._compute_metrics(
            all_gt_classes, all_pred_classes,
            all_gt_parents, all_pred_parents,
            all_gt_relations, all_pred_relations,
        )

        output.num_samples = num_samples
        output.num_lines = len(all_gt_classes)
        output.num_parent_pairs = len(all_gt_parents)
        output.num_relation_pairs = len(all_gt_relations)

        # è®¡ç®— TEDS åˆ†æ•°
        if compute_teds and TEDS_AVAILABLE and teds_gt_docs and teds_pred_docs:
            try:
                print(f"\n[Evaluator] Computing TEDS for {len(teds_gt_docs)} documents...")
                teds_score = compute_teds_score(teds_gt_docs, teds_pred_docs)
                if teds_score is not None:
                    output.teds_score = teds_score
                    print(f"[Evaluator] TEDS Score: {teds_score:.4f}")
            except Exception as e:
                print(f"[Evaluator] TEDS computation failed: {e}")
        elif compute_teds and not TEDS_AVAILABLE:
            print("[Evaluator] TEDS computation skipped: util/hrdoc_eval.py not available")

        # ä¿å­˜é¢„æµ‹ç»“æœï¼ˆæŒ‰æ–‡æ¡£ä¿å­˜åˆ°æ—¶é—´æˆ³ç›®å½•ï¼‰
        if save_predictions and all_predictions:
            import json
            from datetime import datetime

            # åˆ›å»ºæ—¶é—´æˆ³ç›®å½•: runs/{timestamp}/
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            runs_dir = output_dir or os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))), "runs")
            save_dir = os.path.join(runs_dir, timestamp)
            os.makedirs(save_dir, exist_ok=True)

            # æŒ‰æ–‡æ¡£ä¿å­˜
            for doc_pred in all_predictions:
                doc_name = doc_pred["document_name"]
                doc_lines = doc_pred["lines"]
                output_file = os.path.join(save_dir, f"{doc_name}_infer.json")
                with open(output_file, "w", encoding="utf-8") as f:
                    json.dump(doc_lines, f, ensure_ascii=False, indent=2)

            print(f"\n[Evaluator] Predictions saved to: {save_dir}/ ({len(all_predictions)} documents)")

        self.predictor.model.train()
        return output

    def _print_parent_confusion_matrix(self, stats: List[Dict]) -> None:
        """
        ä»¥è¡¨æ ¼æ ¼å¼æ‰“å° Parent æ··æ·†çŸ©é˜µ

        æ ¼å¼ç¤ºä¾‹ï¼š
        +-------------+-------------+----------+-------------------------+
        | Child Class | GT Parent   | Acc      | Mispredictions          |
        +-------------+-------------+----------+-------------------------+
        | fstline     | fstline     | 90% (587/652) | section:54, paraline:11 |
        ...
        """
        confusion = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))
        for item in stats:
            child_cls = item["child_class"]
            gt_p_cls = item["gt_parent_class"]
            pred_p_cls = item["pred_parent_class"]
            confusion[child_cls][gt_p_cls][pred_p_cls] += 1

        # æ”¶é›†æ‰€æœ‰éœ€è¦æ˜¾ç¤ºçš„è¡Œï¼ˆåªæ˜¾ç¤ºæœ‰é”™è¯¯çš„ï¼‰
        rows = []
        for child_cls in sorted(confusion.keys()):
            child_name = self.id2label.get(child_cls, f"cls_{child_cls}")

            for gt_p_cls in sorted(confusion[child_cls].keys(), key=lambda x: (x is None, x)):
                gt_p_name = self.id2label.get(gt_p_cls, f"cls_{gt_p_cls}") if gt_p_cls is not None else "ROOT"
                pred_counts = confusion[child_cls][gt_p_cls]
                total = sum(pred_counts.values())
                correct = pred_counts.get(gt_p_cls, 0)

                # åªæ˜¾ç¤ºæœ‰é”™è¯¯çš„æƒ…å†µ
                if correct < total:
                    error_count = total - correct

                    # æ”¶é›†é”™è¯¯è¯¦æƒ…ï¼ŒæŒ‰æ•°é‡ä»å¤§åˆ°å°æ’åº
                    errors_detail = []
                    for pred_p_cls, cnt in sorted(pred_counts.items(), key=lambda x: -x[1]):
                        if pred_p_cls != gt_p_cls:
                            pred_p_name = self.id2label.get(pred_p_cls, f"cls_{pred_p_cls}") if pred_p_cls is not None else "ROOT"
                            errors_detail.append(f"{pred_p_name}:{cnt}")

                    acc_pct = 100 * correct / total if total > 0 else 0
                    rows.append({
                        'child_name': child_name,
                        'gt_name': gt_p_name,
                        'acc_pct': acc_pct,
                        'correct': correct,
                        'total': total,
                        'error_count': error_count,
                        'errors_detail': ', '.join(errors_detail),
                    })

        # æŒ‰é”™è¯¯æ•°é‡ä»å¤§åˆ°å°æ’åº
        rows.sort(key=lambda x: -x['error_count'])

        if not rows:
            print(f"[Evaluator Debug] Parent Confusion Matrix: No errors found")
            return

        # è®¡ç®—åˆ—å®½
        col_widths = {
            'child': max(13, max(len(row['child_name']) for row in rows) + 2) if rows else 13,
            'gt': max(13, max(len(row['gt_name']) for row in rows) + 2) if rows else 13,
            'acc': max(10, 12),  # "90% (587/652)"
            'errors': max(25, max(len(row['errors_detail']) for row in rows) + 2) if rows else 25,
        }

        # æ‰“å°è¡¨æ ¼
        print(f"\n[Evaluator Debug] Parent Confusion Matrix:")

        # ä¸Šè¾¹æ¡†
        total_width = sum(col_widths.values()) + 7  # 3 separators + 2 edges
        print('+' + '-' * (col_widths['child'] + 1) + '+' + '-' * (col_widths['gt'] + 1) + '+' + '-' * (col_widths['acc'] + 1) + '+' + '-' * (col_widths['errors'] + 1) + '+')

        # è¡¨å¤´
        print('| ' + 'Child Class'.ljust(col_widths['child']) + ' | ' + 'GT Parent'.ljust(col_widths['gt']) + ' | ' + 'Accuracy'.ljust(col_widths['acc']) + ' | ' + 'Mispredictions'.ljust(col_widths['errors']) + ' |')

        # ä¸­é—´åˆ†éš”çº¿
        print('+' + '-' * (col_widths['child'] + 1) + '+' + '-' * (col_widths['gt'] + 1) + '+' + '-' * (col_widths['acc'] + 1) + '+' + '-' * (col_widths['errors'] + 1) + '+')

        # æ•°æ®è¡Œ
        for row in rows:
            acc_str = f"{row['acc_pct']:.0f}% ({row['correct']}/{row['total']})"
            child_str = row['child_name'].ljust(col_widths['child'])
            gt_str = row['gt_name'].ljust(col_widths['gt'])
            acc_str = acc_str.ljust(col_widths['acc'])
            errors_str = row['errors_detail'].ljust(col_widths['errors'])

            print(f"| {child_str} | {gt_str} | {acc_str} | {errors_str} |")

        # ä¸‹è¾¹æ¡†
        print('+' + '-' * (col_widths['child'] + 1) + '+' + '-' * (col_widths['gt'] + 1) + '+' + '-' * (col_widths['acc'] + 1) + '+' + '-' * (col_widths['errors'] + 1) + '+')

    def _print_section_stats(self, stats: List[Dict], gt_class_counter: Dict, pred_class_counter: Dict) -> None:
        """
        æ‰“å° Section ç±»åˆ«çš„è¯¦ç»†ç»Ÿè®¡è¡¨æ ¼

        åŒ…æ‹¬ï¼š
        1. Section åˆ†ç±»ç»Ÿè®¡
        2. Section Parent å‡†ç¡®ç‡
        3. Section é”™è¯¯è¯¦æƒ…
        """
        SECTION_ID = LABEL2ID.get("section", 2)

        # ç­›é€‰ section ç›¸å…³çš„ç»Ÿè®¡
        section_stats = [s for s in stats if s["child_class"] == SECTION_ID]
        if not section_stats:
            return

        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        section_total = len(section_stats)
        section_correct = sum(1 for s in section_stats if s["is_correct"])
        section_acc = 100 * section_correct / section_total if section_total > 0 else 0

        # é”™è¯¯åˆ†æ
        section_errors = [s for s in section_stats if not s["is_correct"]]
        error_by_pred_class = defaultdict(int)
        for e in section_errors:
            pred_cls = e["pred_parent_class"]
            pred_name = self.id2label.get(pred_cls, "ROOT") if pred_cls is not None else "ROOT"
            error_by_pred_class[pred_name] += 1

        # GT/Pred ç±»åˆ«ç»Ÿè®¡
        gt_section_count = gt_class_counter.get(SECTION_ID, 0)
        pred_section_count = pred_class_counter.get(SECTION_ID, 0)

        # æŒ‰ gt_parent_class åˆ†ç»„ç»Ÿè®¡
        parent_class_stats = defaultdict(lambda: {"correct": 0, "total": 0, "errors": defaultdict(int)})
        for s in section_stats:
            gt_p_cls = s["gt_parent_class"]
            gt_p_name = self.id2label.get(gt_p_cls, "ROOT") if gt_p_cls is not None else "ROOT"
            parent_class_stats[gt_p_name]["total"] += 1
            if s["is_correct"]:
                parent_class_stats[gt_p_name]["correct"] += 1
            else:
                pred_p_cls = s["pred_parent_class"]
                pred_p_name = self.id2label.get(pred_p_cls, "ROOT") if pred_p_cls is not None else "ROOT"
                parent_class_stats[gt_p_name]["errors"][pred_p_name] += 1

        # æ‰“å°è¡¨æ ¼
        print("\n" + "=" * 70)
        print("  ğŸ“Š SECTION ç±»åˆ«è¯¦ç»†ç»Ÿè®¡")
        print("=" * 70)

        # 1. åˆ†ç±»ç»Ÿè®¡
        print("\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
        print("â”‚ 1. Section åˆ†ç±»ç»Ÿè®¡                                                 â”‚")
        print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
        diff = pred_section_count - gt_section_count
        diff_str = f"+{diff}" if diff > 0 else str(diff) if diff < 0 else "0"
        print(f"â”‚   GT Section æ•°é‡:    {gt_section_count:<6}                                       â”‚")
        print(f"â”‚   Pred Section æ•°é‡:  {pred_section_count:<6} ({diff_str})                                     â”‚")
        print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")

        # 2. Parent å‡†ç¡®ç‡
        print("\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
        print("â”‚ 2. Section Parent é¢„æµ‹å‡†ç¡®ç‡                                        â”‚")
        print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
        bar_len = 30
        filled = int(bar_len * section_acc / 100)
        bar = "â–ˆ" * filled + "â–‘" * (bar_len - filled)
        print(f"â”‚   å‡†ç¡®ç‡: {section_acc:5.1f}%  [{bar}]  {section_correct}/{section_total}    â”‚")
        print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")

        # 3. æŒ‰ GT Parent ç±»å‹åˆ†ç»„ç»Ÿè®¡
        print("\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
        print("â”‚ 3. Section Parent æŒ‰ GT Parent ç±»å‹åˆ†ç»„                             â”‚")
        print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
        print("â”‚ GT Parent     â”‚ æ­£ç¡®/æ€»æ•° â”‚ å‡†ç¡®ç‡    â”‚ è¯¯åˆ¤åˆ†å¸ƒ                      â”‚")
        print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")

        for gt_p_name in sorted(parent_class_stats.keys()):
            pstat = parent_class_stats[gt_p_name]
            p_acc = 100 * pstat["correct"] / pstat["total"] if pstat["total"] > 0 else 0
            count_str = f"{pstat['correct']}/{pstat['total']}"

            # é”™è¯¯åˆ†å¸ƒ
            if pstat["errors"]:
                err_list = [f"{k}:{v}" for k, v in sorted(pstat["errors"].items(), key=lambda x: -x[1])]
                err_str = ", ".join(err_list)
            else:
                err_str = "-"

            print(f"â”‚ {gt_p_name:<13} â”‚ {count_str:<8} â”‚ {p_acc:>6.1f}%   â”‚ {err_str:<29} â”‚")

        print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")

        # 4. é”™è¯¯æ±‡æ€»
        if section_errors:
            print("\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
            print("â”‚ 4. Section Parent é”™è¯¯æ±‡æ€»                                          â”‚")
            print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
            print(f"â”‚   æ€»é”™è¯¯æ•°: {len(section_errors):<6}                                              â”‚")
            print("â”‚   è¯¯åˆ¤ä¸º:                                                           â”‚")
            for pred_name, cnt in sorted(error_by_pred_class.items(), key=lambda x: -x[1]):
                pct = 100 * cnt / len(section_errors)
                print(f"â”‚     - {pred_name:<10}: {cnt:>3} ({pct:>5.1f}%)                                    â”‚")
            print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")

            # 5. é”™è¯¯è¯¦æƒ…ï¼ˆå¸¦æ–‡æœ¬ï¼‰
            self._print_section_error_details(section_errors)

        print("=" * 70 + "\n")

    def _print_section_error_details(self, section_errors: List[Dict]) -> None:
        """
        æ‰“å° Section é”™è¯¯è¯¦æƒ…ï¼ˆå¸¦æ–‡æœ¬ä¿¡æ¯ï¼‰
        """
        import json

        # åŠ è½½åŸå§‹æ•°æ®ç¼“å­˜
        doc_line_texts = {}  # {doc_name: {line_id: text}}

        def load_doc_texts(doc_name: str) -> Dict[int, str]:
            """ä»åŸå§‹ JSON åŠ è½½æ–‡æ¡£çš„è¡Œæ–‡æœ¬"""
            if doc_name in doc_line_texts:
                return doc_line_texts[doc_name]

            line_texts = {}
            json_path = self._doc_json_paths.get(doc_name)

            if json_path and os.path.exists(json_path):
                try:
                    with open(json_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)

                    # å¤„ç†å¤šé¡µé¢æ ¼å¼ï¼ˆpages æ•°ç»„ï¼‰
                    if "pages" in data:
                        for page in data["pages"]:
                            items = page.get("items", page.get("lines", []))
                            for item in items:
                                line_id = item.get("line_id", item.get("id"))
                                if line_id is not None:
                                    words = item.get("words", [])
                                    if words:
                                        text = " ".join(w.get("text", "") for w in words)
                                    else:
                                        text = item.get("text", "")
                                    line_texts[line_id] = text[:50]  # æˆªæ–­
                    else:
                        # å•é¡µé¢æ ¼å¼
                        items = data.get("items", data.get("lines", []))
                        for item in items:
                            line_id = item.get("line_id", item.get("id"))
                            if line_id is not None:
                                words = item.get("words", [])
                                if words:
                                    text = " ".join(w.get("text", "") for w in words)
                                else:
                                    text = item.get("text", "")
                                line_texts[line_id] = text[:50]
                except Exception as e:
                    pass  # å¿½ç•¥åŠ è½½é”™è¯¯

            doc_line_texts[doc_name] = line_texts
            return line_texts

        print("\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
        print("â”‚ 5. Section Parent é”™è¯¯è¯¦æƒ…                                                                      â”‚")
        print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")

        for i, err in enumerate(section_errors[:10]):  # åªæ˜¾ç¤ºå‰ 10 ä¸ª
            doc_name = err.get("document_name", "unknown")
            json_path = self._doc_json_paths.get(doc_name, "")
            line_texts = load_doc_texts(doc_name)

            child_line_id = err.get("child_line_id", -1)
            gt_parent_line_id = err.get("gt_parent_line_id", -1)
            pred_parent_line_id = err.get("pred_parent_line_id", -1)

            child_text = line_texts.get(child_line_id, "N/A")
            gt_parent_text = line_texts.get(gt_parent_line_id, "ROOT" if gt_parent_line_id == -1 else "N/A")
            pred_parent_text = line_texts.get(pred_parent_line_id, "ROOT" if pred_parent_line_id == -1 else "N/A")

            gt_p_cls = err.get("gt_parent_class")
            pred_p_cls = err.get("pred_parent_class")
            gt_p_name = self.id2label.get(gt_p_cls, "ROOT") if gt_p_cls is not None else "ROOT"
            pred_p_name = self.id2label.get(pred_p_cls, "ROOT") if pred_p_cls is not None else "ROOT"

            print(f"â”‚ [{i+1}] æ–‡æ¡£: {doc_name}")
            if json_path:
                print(f"â”‚     æ–‡ä»¶: {json_path}")
            print(f"â”‚     å½“å‰è¡Œ (id={child_line_id}): \"{child_text}\"")
            print(f"â”‚     âœ“ GT Parent   (id={gt_parent_line_id}, {gt_p_name}): \"{gt_parent_text}\"")
            print(f"â”‚     âœ— Pred Parent (id={pred_parent_line_id}, {pred_p_name}): \"{pred_parent_text}\"")
            if i < len(section_errors) - 1 and i < 9:
                print("â”‚" + "â”€" * 97 + "â”‚")

        if len(section_errors) > 10:
            print(f"â”‚     ... è¿˜æœ‰ {len(section_errors) - 10} ä¸ªé”™è¯¯æœªæ˜¾ç¤º                                                        â”‚")

        print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")

    def _extract_gt(self, sample: Sample) -> Dict[str, Any]:
        """
        ä» Sample ä¸­æå– Ground Truth

        Returns:
            {
                "classes": {line_id: class_id, ...},
                "parents": [parent_id, ...],
                "relations": [relation_id, ...],
                "line_ids": [line_id, ...],  # æ¯ä¸ªä½ç½®å¯¹åº”çš„å®é™… line_id
            }
        """
        gt = {
            "classes": {},
            "parents": [],
            "relations": [],
            "line_ids": [],  # ç”¨äºæ­£ç¡®æ¯”è¾ƒ parent_id å’Œ child_id
        }

        if sample.line_ids is None:
            return gt

        # æå– line_ids å’Œ labelsï¼ˆå±•å¹³å¤„ç†å¤š chunk æƒ…å†µï¼‰
        if sample.is_document_level:
            all_line_ids = sample.line_ids.reshape(-1).cpu().tolist()
            all_labels = sample.labels.reshape(-1).cpu().tolist() if sample.labels is not None else []
        else:
            all_line_ids = sample.line_ids.cpu().tolist()
            all_labels = sample.labels.cpu().tolist() if sample.labels is not None else []

        # æå– sorted_line_idsï¼ˆä¸ predictor çš„ LinePooling.get_line_ids_mapping ä¸€è‡´ï¼‰
        unique_line_ids = sorted(set(lid for lid in all_line_ids if lid >= 0))

        # æå–åˆ†ç±» GT
        if sample.line_labels is not None:
            # ä¼˜å…ˆä½¿ç”¨ line_labelsï¼ˆè¡Œç´¢å¼•ç›´æ¥å¯¹åº”ï¼‰
            labels = sample.line_labels.cpu().tolist()
            for line_idx, label in enumerate(labels):
                if label >= 0 and label != -100:
                    # line_labels æŒ‰è¡Œåºå·ç´¢å¼•ï¼Œéœ€è¦æ˜ å°„åˆ° line_id
                    if line_idx < len(unique_line_ids):
                        line_id = unique_line_ids[line_idx]
                        gt["classes"][line_id] = label
        elif all_labels:
            # Fallback: ä» token labels æå–ï¼ˆé¦–æ¬¡å‡ºç°ç­–ç•¥ï¼‰
            for label, line_id in zip(all_labels, all_line_ids):
                if line_id >= 0 and label >= 0 and line_id not in gt["classes"]:
                    gt["classes"][line_id] = label

        # å¤„ç† parent_ids å’Œ relations
        # é‡è¦ï¼š
        # 1. sample.line_parent_ids æŒ‰è¡Œåºå·ç´¢å¼•ï¼ˆ0, 1, 2, ...ï¼‰ï¼Œä¸æ˜¯æŒ‰ line_id ç´¢å¼•
        # 2. sample.line_parent_ids çš„å€¼æ˜¯ parent çš„ line_idï¼Œéœ€è¦è½¬æ¢ä¸ºè¡Œåºå·
        # 3. pred.line_parents æ˜¯è¡Œåºå·ï¼Œæ‰€ä»¥ GT ä¹Ÿè¦ç”¨è¡Œåºå·è¡¨ç¤º

        # å»ºç«‹ line_id -> è¡Œåºå· çš„æ˜ å°„ï¼ˆä½¿ç”¨ sorted é¡ºåºï¼Œä¸ predictor ä¸€è‡´ï¼‰
        line_id_to_row = {lid: row for row, lid in enumerate(unique_line_ids)}

        if sample.line_parent_ids is not None:
            raw_parents = sample.line_parent_ids.cpu().tolist()
            # æŒ‰è¡Œåºå·é¡ºåºæå–ï¼Œå¹¶å°† parent_line_id è½¬æ¢ä¸ºè¡Œåºå·
            for row in range(len(unique_line_ids)):
                if row < len(raw_parents):
                    parent_line_id = raw_parents[row]
                    if parent_line_id == -1:
                        gt["parents"].append(-1)  # ROOT
                    elif parent_line_id == -100:
                        gt["parents"].append(-100)  # padding
                    elif parent_line_id in line_id_to_row:
                        gt["parents"].append(line_id_to_row[parent_line_id])
                    else:
                        # parent çš„ line_id ä¸åœ¨å½“å‰æ–‡æ¡£ä¸­ï¼ˆå¯èƒ½æ˜¯è·¨é¡µè¢«æˆªæ–­ï¼‰
                        gt["parents"].append(-1)  # è§†ä¸º ROOT
                else:
                    gt["parents"].append(-100)  # padding

        if sample.line_relations is not None:
            raw_relations = sample.line_relations.cpu().tolist()
            # æŒ‰è¡Œåºå·é¡ºåºæå–
            for row in range(len(unique_line_ids)):
                if row < len(raw_relations):
                    gt["relations"].append(raw_relations[row])
                else:
                    gt["relations"].append(-100)

        # å­˜å‚¨æ’åºåçš„ line_idsï¼ˆä¸ predictor ä¸€è‡´ï¼‰
        gt["line_ids"] = unique_line_ids

        return gt

    def _compute_metrics(
        self,
        gt_classes: List[int],
        pred_classes: List[int],
        gt_parents: List[int],
        pred_parents: List[int],
        gt_relations: List[int],
        pred_relations: List[int],
    ) -> EvaluationOutput:
        """è®¡ç®—æ‰€æœ‰æŒ‡æ ‡"""
        output = EvaluationOutput()

        # Stage 1: åˆ†ç±»æŒ‡æ ‡
        if gt_classes:
            output.line_accuracy = self._accuracy(gt_classes, pred_classes)
            output.line_macro_f1 = self._macro_f1(gt_classes, pred_classes)
            output.line_micro_f1 = self._micro_f1(gt_classes, pred_classes)

        # Stage 3: Parent å‡†ç¡®ç‡
        if gt_parents:
            output.parent_accuracy = self._accuracy(gt_parents, pred_parents)

        # Stage 4: Relation æŒ‡æ ‡
        if gt_relations:
            output.relation_accuracy = self._accuracy(gt_relations, pred_relations)
            output.relation_macro_f1 = self._macro_f1(
                gt_relations, pred_relations, num_classes=3
            )
            output.relation_micro_f1 = self._micro_f1(gt_relations, pred_relations)

        return output

    def _accuracy(self, gt: List[int], pred: List[int]) -> float:
        """è®¡ç®—å‡†ç¡®ç‡"""
        if not gt:
            return 0.0
        correct = sum(g == p for g, p in zip(gt, pred))
        return correct / len(gt)

    def _macro_f1(
        self,
        gt: List[int],
        pred: List[int],
        num_classes: int = None
    ) -> float:
        """è®¡ç®— Macro F1"""
        if not gt:
            return 0.0

        if num_classes is None:
            num_classes = max(max(gt), max(pred)) + 1

        f1_scores = []
        for c in range(num_classes):
            tp = sum(1 for g, p in zip(gt, pred) if g == c and p == c)
            fp = sum(1 for g, p in zip(gt, pred) if g != c and p == c)
            fn = sum(1 for g, p in zip(gt, pred) if g == c and p != c)

            precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0
            recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0

            if precision + recall > 0:
                f1 = 2 * precision * recall / (precision + recall)
            else:
                f1 = 0.0

            if tp + fn > 0:  # åªè®¡ç®—æœ‰æ ·æœ¬çš„ç±»åˆ«
                f1_scores.append(f1)

        return sum(f1_scores) / len(f1_scores) if f1_scores else 0.0

    def _micro_f1(self, gt: List[int], pred: List[int]) -> float:
        """è®¡ç®— Micro F1ï¼ˆç­‰äº accuracyï¼‰"""
        return self._accuracy(gt, pred)

    def print_results(self, output: EvaluationOutput):
        """æ‰“å°è¯„ä¼°ç»“æœ"""
        print("=" * 60)
        print("Evaluation Results")
        print("=" * 60)
        print(f"  Samples: {output.num_samples}")
        print(f"  Lines:   {output.num_lines}")
        print("-" * 60)
        print(f"  Stage 1 (Classification):")
        print(f"    Accuracy:  {output.line_accuracy * 100:.2f}%")
        print(f"    Macro F1:  {output.line_macro_f1 * 100:.2f}%")
        print("-" * 60)
        print(f"  Stage 3 (Parent):")
        print(f"    Accuracy:  {output.parent_accuracy * 100:.2f}%")
        print(f"    Pairs:     {output.num_parent_pairs}")
        print("-" * 60)
        print(f"  Stage 4 (Relation):")
        print(f"    Accuracy:  {output.relation_accuracy * 100:.2f}%")
        print(f"    Macro F1:  {output.relation_macro_f1 * 100:.2f}%")
        print(f"    Pairs:     {output.num_relation_pairs}")
        print("=" * 60)
