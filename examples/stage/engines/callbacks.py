#!/usr/bin/env python
# coding=utf-8
"""
è®­ç»ƒå›è°ƒå‡½æ•°

åŒ…å«ï¼š
- AMPDiagnosticCallback: ç›‘æ§ AMP GradScaler çŠ¶æ€
- JointLoggingCallback: ç¾åŒ–è®­ç»ƒæ—¥å¿—è¾“å‡º
- E2EEvaluationCallback: ç«¯åˆ°ç«¯è¯„ä¼°å›è°ƒ (Stage 1/3/4)
- Stage1EvaluationCallback: Stage1 åˆ†ç±»è¯„ä¼°å›è°ƒ
"""

import logging
import os
from typing import Dict, Optional

import torch
from transformers import TrainerCallback

logger = logging.getLogger(__name__)


class AMPDiagnosticCallback(TrainerCallback):
    """
    ç›‘æ§ AMP GradScaler çŠ¶æ€ï¼Œç”¨äºè¯Šæ–­ fp16 æº¢å‡ºé—®é¢˜

    å·¥ä¸šå®è·µï¼šå½“ scale ä¸‹é™æ—¶ï¼Œé€šå¸¸æ„å‘³ç€æ£€æµ‹åˆ°äº† overflow å¹¶è·³è¿‡äº†è¯¥æ­¥æ›´æ–°
    """

    def __init__(self):
        self.prev_scale = None
        self.overflow_count = 0
        self.scaler = None

    def on_train_begin(self, args, state, control, **kwargs):
        """è®­ç»ƒå¼€å§‹æ—¶å°è¯•è·å– scaler å¼•ç”¨"""
        import gc
        for obj in gc.get_objects():
            if isinstance(obj, torch.cuda.amp.GradScaler):
                self.scaler = obj
                logger.info(f"[AMP-DIAG] Found GradScaler, initial scale={self.scaler.get_scale():.1f}")
                break

    def on_step_end(self, args, state, control, **kwargs):
        """æ¯æ­¥ç»“æŸåæ£€æŸ¥ GradScaler çŠ¶æ€"""
        if self.scaler is None:
            return

        try:
            current_scale = self.scaler.get_scale()
            if self.prev_scale is not None:
                if current_scale < self.prev_scale:
                    self.overflow_count += 1
                    logger.warning(
                        f"[AMP-DIAG] Step {state.global_step}: "
                        f"Scale decreased {self.prev_scale:.1f} -> {current_scale:.1f} "
                        f"(overflow detected, total overflows: {self.overflow_count})"
                    )
            self.prev_scale = current_scale

            # æ¯ 500 æ­¥æ‰“å°ä¸€æ¬¡ scale çŠ¶æ€
            if state.global_step % 500 == 0:
                logger.info(f"[AMP-DIAG] Step {state.global_step}: scale={current_scale:.1f}, total_overflows={self.overflow_count}")
        except Exception:
            pass  # scaler å¯èƒ½ä¸å¯ç”¨


class JointLoggingCallback(TrainerCallback):
    """è®°å½•è”åˆè®­ç»ƒçš„è¯¦ç»†æ—¥å¿—ï¼ˆç¾åŒ–ç‰ˆï¼‰"""

    def __init__(self, total_steps: int = None, mode: str = "joint"):
        self.total_steps = total_steps
        self.mode = mode
        self.best_parent_acc = 0.0
        self.best_rel_acc = 0.0

    def on_log(self, args, state, control, logs=None, **kwargs):
        if logs is None:
            return

        step = state.global_step
        total = self.total_steps or state.max_steps or 1

        # è·³è¿‡æ²¡æœ‰ loss çš„æ—¥å¿—ï¼ˆå¦‚ eval ç»“æœï¼‰
        if "loss" not in logs:
            return

        # è¿›åº¦æ¡
        progress = step / total
        bar_width = 20
        filled = int(bar_width * progress)
        bar = "â–ˆ" * filled + "â–‘" * (bar_width - filled)

        # å­¦ä¹ ç‡ï¼ˆä» logs æˆ– state è·å–ï¼‰
        lr = logs.get("learning_rate")
        if lr is None and hasattr(state, 'last_lr') and state.last_lr is not None:
            lr = state.last_lr
        if lr is None:
            lr = args.learning_rate
        lr_str = f"{lr:.2e}" if lr and lr > 0 else "N/A"

        # æ„å»ºè¾“å‡º
        header = f"Step {step:>5}/{total} [{bar}] {progress*100:>5.1f}%  lr={lr_str}"

        if self.mode == "stage1":
            # Stage1 æ¨¡å¼ï¼šåªæ˜¾ç¤ºåˆ†ç±» loss
            cls_loss = logs.get("cls_loss", logs.get("loss", 0))
            tasks = f"  loss={logs['loss']:.4f}  â”‚  cls={cls_loss:.3f}"
        else:
            # Joint/Stage34 æ¨¡å¼ï¼šæ˜¾ç¤ºå…¨éƒ¨æŒ‡æ ‡
            cls_loss = logs.get("cls_loss", 0)
            parent_loss = logs.get("parent_loss", 0)
            rel_loss = logs.get("rel_loss", 0)
            parent_acc = logs.get("parent_acc", 0)
            rel_acc = logs.get("rel_acc", 0)

            # æ›´æ–°æœ€ä½³
            if parent_acc > self.best_parent_acc:
                self.best_parent_acc = parent_acc
            if rel_acc > self.best_rel_acc:
                self.best_rel_acc = rel_acc

            # ä»»åŠ¡æŒ‡æ ‡ï¼ˆå¸¦è¶‹åŠ¿æŒ‡ç¤ºï¼‰
            parent_indicator = "â–²" if parent_acc >= self.best_parent_acc else " "
            rel_indicator = "â–²" if rel_acc >= self.best_rel_acc else " "

            tasks = (
                f"  loss={logs['loss']:.4f}  â”‚  "
                f"cls={cls_loss:.3f}  â”‚  "
                f"parent={parent_loss:.3f} ({parent_acc:>5.1%}){parent_indicator}  â”‚  "
                f"rel={rel_loss:.3f} ({rel_acc:>5.1%}){rel_indicator}"
            )

        logger.info(header)
        logger.info(tasks)


class E2EEvaluationCallback(TrainerCallback):
    """
    ç«¯åˆ°ç«¯è¯„ä¼° Callback (Stage 1/3/4)

    åœ¨æ¯æ¬¡è¯„ä¼°æ—¶è¿è¡Œå®Œæ•´çš„ç«¯åˆ°ç«¯è¯„ä¼°ï¼š
    - Stage 1: åˆ†ç±» (Line-level Macro/Micro F1)
    - Stage 3: Parent å‡†ç¡®ç‡
    - Stage 4: Relation å‡†ç¡®ç‡ + Macro F1

    ä½¿ç”¨ engines/evaluator.py ç»Ÿä¸€æ¥å£
    """

    def __init__(
        self,
        eval_dataloader,
        data_collator=None,
        compute_teds: bool = False,
        save_predictions: bool = False,
        output_dir: str = None,
        # Best model ä¿å­˜é…ç½®
        best_model_metric: str = "parent_accuracy",
        trainer=None,  # JointTrainer å®ä¾‹ï¼Œç”¨äºä¿å­˜æ¨¡å‹
    ):
        self.eval_dataloader = eval_dataloader
        self.data_collator = data_collator
        self.compute_teds = compute_teds
        self.save_predictions = save_predictions
        self.output_dir = output_dir

        # Best model é…ç½®ï¼ˆå§‹ç»ˆä¿å­˜ï¼ŒæŒ‡æ ‡è¶Šå¤§è¶Šå¥½ï¼‰
        self.best_model_metric = best_model_metric
        self.trainer = trainer
        self.best_metric_value = float('-inf')
        self.best_step = None

        # å†å²è¯„ä¼°è®°å½•ï¼š[(step, line_macro, line_micro, line_acc, parent_acc, rel_macro, rel_micro, rel_acc, teds, sec_parent, sec_rel), ...]
        self.history = []

    def on_evaluate(self, args, state, control, model=None, **kwargs):
        """åœ¨ Trainer.evaluate() ä¹‹åè¿è¡Œç«¯åˆ°ç«¯è¯„ä¼°"""
        if model is None:
            return

        device = next(model.parameters()).device
        global_step = state.global_step

        logger.info("")
        logger.info("=" * 60)
        logger.info(f"End-to-End Evaluation (Stage 1/3/4) at Step {global_step}")
        logger.info("=" * 60)

        # ä½¿ç”¨ Evaluatorï¼ˆç»Ÿä¸€æ¥å£ï¼Œæ”¯æŒ page/doc çº§åˆ«ï¼‰
        from .evaluator import Evaluator

        evaluator = Evaluator(model, device)
        output = evaluator.evaluate(
            self.eval_dataloader,
            compute_teds=self.compute_teds,
            verbose=True,
            save_predictions=self.save_predictions,
            output_dir=self.output_dir,
        )

        # æ‰“å°ç»“æœ
        line_macro = output.line_macro_f1 * 100
        line_micro = output.line_micro_f1 * 100
        line_acc = output.line_accuracy * 100
        parent_acc = output.parent_accuracy * 100
        rel_acc = output.relation_accuracy * 100
        rel_macro = output.relation_macro_f1 * 100
        rel_micro = output.relation_micro_f1 * 100
        teds = output.teds_score * 100 if output.teds_score is not None else None
        num_lines = output.num_lines
        # Section æŒ‡æ ‡
        sec_parent_acc = output.section_parent_accuracy * 100
        sec_rel_acc = output.section_relation_accuracy * 100
        sec_edge_acc = output.section_edge_accuracy * 100

        def fmt_delta(d, threshold=0.5):
            if d >= threshold:
                return f"â†‘{d:+.1f}"
            elif d <= -threshold:
                return f"â†“{d:+.1f}"
            else:
                return f" {d:+.1f}"

        avg_n = min(3, len(self.history))

        logger.info("")
        logger.info("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
        logger.info(f"â•‘              Evaluation Results @ Step {global_step:<6}                        â•‘")
        logger.info("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")

        if avg_n > 0:
            recent = self.history[-avg_n:]
            avg_line_macro = sum(h[1] for h in recent) / avg_n
            avg_line_micro = sum(h[2] for h in recent) / avg_n
            avg_line_acc = sum(h[3] for h in recent) / avg_n
            avg_parent = sum(h[4] for h in recent) / avg_n
            avg_rel_macro = sum(h[5] for h in recent) / avg_n
            avg_rel_micro = sum(h[6] for h in recent) / avg_n
            avg_rel_acc = sum(h[7] for h in recent) / avg_n
            avg_sec_parent = sum(h[9] for h in recent) / avg_n
            avg_sec_rel = sum(h[10] for h in recent) / avg_n
            avg_sec_edge = sum(h[11] for h in recent) / avg_n

            delta_line_macro = line_macro - avg_line_macro
            delta_line_micro = line_micro - avg_line_micro
            delta_line_acc = line_acc - avg_line_acc
            delta_parent = parent_acc - avg_parent
            delta_rel_macro = rel_macro - avg_rel_macro
            delta_rel_micro = rel_micro - avg_rel_micro
            delta_rel_acc = rel_acc - avg_rel_acc
            delta_sec_parent = sec_parent_acc - avg_sec_parent
            delta_sec_rel = sec_rel_acc - avg_sec_rel
            delta_sec_edge = sec_edge_acc - avg_sec_edge

            logger.info(f"â•‘  Metric          â”‚ Current  â”‚  Avg({avg_n})  â”‚  Delta       â•‘")
            logger.info("â•‘â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•‘")
            logger.info(f"â•‘  Line(MacroF1)   â”‚  {line_macro:>5.1f}%  â”‚  {avg_line_macro:>5.1f}%  â”‚  {fmt_delta(delta_line_macro):>6}      â•‘")
            logger.info(f"â•‘  Line(MicroF1)   â”‚  {line_micro:>5.1f}%  â”‚  {avg_line_micro:>5.1f}%  â”‚  {fmt_delta(delta_line_micro):>6}      â•‘")
            logger.info(f"â•‘  Line(Acc)       â”‚  {line_acc:>5.1f}%  â”‚  {avg_line_acc:>5.1f}%  â”‚  {fmt_delta(delta_line_acc):>6}      â•‘")
            logger.info(f"â•‘  Parent(Acc)     â”‚  {parent_acc:>5.1f}%  â”‚  {avg_parent:>5.1f}%  â”‚  {fmt_delta(delta_parent):>6}      â•‘")
            logger.info(f"â•‘  Sec-Parent(Acc) â”‚  {sec_parent_acc:>5.1f}%  â”‚  {avg_sec_parent:>5.1f}%  â”‚  {fmt_delta(delta_sec_parent):>6}      â•‘")
            logger.info(f"â•‘  Rel(MacroF1)    â”‚  {rel_macro:>5.1f}%  â”‚  {avg_rel_macro:>5.1f}%  â”‚  {fmt_delta(delta_rel_macro):>6}      â•‘")
            logger.info(f"â•‘  Rel(MicroF1)    â”‚  {rel_micro:>5.1f}%  â”‚  {avg_rel_micro:>5.1f}%  â”‚  {fmt_delta(delta_rel_micro):>6}      â•‘")
            logger.info(f"â•‘  Rel(Acc)        â”‚  {rel_acc:>5.1f}%  â”‚  {avg_rel_acc:>5.1f}%  â”‚  {fmt_delta(delta_rel_acc):>6}      â•‘")
            logger.info(f"â•‘  Sec-Rel(Acc)    â”‚  {sec_rel_acc:>5.1f}%  â”‚  {avg_sec_rel:>5.1f}%  â”‚  {fmt_delta(delta_sec_rel):>6}      â•‘")
            logger.info(f"â•‘  Sec-Edge(Acc) â˜… â”‚  {sec_edge_acc:>5.1f}%  â”‚  {avg_sec_edge:>5.1f}%  â”‚  {fmt_delta(delta_sec_edge):>6}      â•‘")

            summary = f"[Step {global_step}] Line={line_macro:.1f}% | Parent={parent_acc:.1f}% ({fmt_delta(delta_parent)}) | SecEdge={sec_edge_acc:.1f}% ({fmt_delta(delta_sec_edge)})"
        else:
            logger.info(f"â•‘  Metric          â”‚ Current  â”‚                           â•‘")
            logger.info("â•‘â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•‘")
            logger.info(f"â•‘  Line(MacroF1)   â”‚  {line_macro:>5.1f}%  â”‚                           â•‘")
            logger.info(f"â•‘  Line(MicroF1)   â”‚  {line_micro:>5.1f}%  â”‚                           â•‘")
            logger.info(f"â•‘  Line(Acc)       â”‚  {line_acc:>5.1f}%  â”‚                           â•‘")
            logger.info(f"â•‘  Parent(Acc)     â”‚  {parent_acc:>5.1f}%  â”‚                           â•‘")
            logger.info(f"â•‘  Sec-Parent(Acc) â”‚  {sec_parent_acc:>5.1f}%  â”‚                           â•‘")
            logger.info(f"â•‘  Rel(MacroF1)    â”‚  {rel_macro:>5.1f}%  â”‚                           â•‘")
            logger.info(f"â•‘  Rel(MicroF1)    â”‚  {rel_micro:>5.1f}%  â”‚                           â•‘")
            logger.info(f"â•‘  Rel(Acc)        â”‚  {rel_acc:>5.1f}%  â”‚                           â•‘")
            logger.info(f"â•‘  Sec-Rel(Acc)    â”‚  {sec_rel_acc:>5.1f}%  â”‚                           â•‘")
            logger.info(f"â•‘  Sec-Edge(Acc) â˜… â”‚  {sec_edge_acc:>5.1f}%  â”‚                           â•‘")
            summary = f"[Step {global_step}] Line={line_macro:.1f}% | Parent={parent_acc:.1f}% | SecEdge={sec_edge_acc:.1f}%"

        # TEDS åˆ†æ•°ï¼ˆå¦‚æœè®¡ç®—äº†ï¼‰
        if teds is not None:
            logger.info("â•‘â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•‘")
            logger.info(f"â•‘  TEDS Score      â”‚  {teds:>5.1f}%  â”‚                           â•‘")
            summary += f" | TEDS={teds:.1f}%"

        logger.info("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        logger.info(f"â•‘  Lines evaluated: {num_lines:<53} â•‘")
        logger.info("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        logger.info(summary)

        # history: (step, line_macro, line_micro, line_acc, parent_acc, rel_macro, rel_micro, rel_acc, teds, sec_parent, sec_rel, sec_edge)
        self.history.append((global_step, line_macro, line_micro, line_acc, parent_acc, rel_macro, rel_micro, rel_acc, teds, sec_parent_acc, sec_rel_acc, sec_edge_acc))

        # Best model ä¿å­˜
        if self.trainer is not None:
            self._maybe_save_best_model(
                global_step=global_step,
                metrics={
                    "parent_accuracy": parent_acc,
                    "relation_macro_f1": rel_macro,
                    "section_parent": sec_parent_acc,
                    "section_edge": sec_edge_acc,  # parent + relation éƒ½å¯¹
                    "teds": teds if teds is not None else 0.0,
                    "line_macro_f1": line_macro,
                },
                model=model,
            )

        # å†™å› metrics dictï¼ˆä¾› Trainer.evaluate() è¿”å›ï¼ŒHF ç”¨äºé€‰ bestï¼‰
        metrics_dict = kwargs.get("metrics", {})
        metrics_dict.update({
            "line_macro_f1": line_macro / 100,
            "line_micro_f1": line_micro / 100,
            "line_accuracy": line_acc / 100,
            "parent_accuracy": parent_acc / 100,
            "relation_macro_f1": rel_macro / 100,
            "relation_accuracy": rel_acc / 100,
            "section_parent": sec_parent_acc / 100,
            "section_edge": sec_edge_acc / 100,
        })
        if teds is not None:
            metrics_dict["teds"] = teds / 100

    def _maybe_save_best_model(self, global_step: int, metrics: dict, model):
        """æ£€æŸ¥æ˜¯å¦éœ€è¦ä¿å­˜ best modelï¼ˆæŒ‡æ ‡è¶Šå¤§è¶Šå¥½ï¼‰"""
        current_value = metrics.get(self.best_model_metric, 0.0)

        if current_value > self.best_metric_value:
            self.best_metric_value = current_value
            self.best_step = global_step

            # ä¿å­˜åˆ° output_dir/best/
            best_dir = os.path.join(self.output_dir, "best")
            logger.info(f"")
            logger.info(f"ğŸ† New best model! {self.best_model_metric}={current_value:.2f}% at step {global_step}")
            logger.info(f"   Saving to: {best_dir}")

            # è°ƒç”¨ trainer çš„ä¿å­˜æ–¹æ³•
            self.trainer._save(output_dir=best_dir)

            # ä¿å­˜ best_info.json è®°å½•å…ƒä¿¡æ¯
            import json
            best_info = {
                "step": global_step,
                "metric": self.best_model_metric,
                "value": current_value,
                "all_metrics": metrics,
            }
            with open(os.path.join(best_dir, "best_info.json"), "w") as f:
                json.dump(best_info, f, indent=2)


class Stage1EvaluationCallback(TrainerCallback):
    """
    Stage1 åˆ†ç±»è¯„ä¼° Callback

    åªè¯„ä¼° Stage1 çš„åˆ†ç±»æŒ‡æ ‡ï¼ˆLine-level Macro/Micro F1ï¼‰ï¼Œ
    ä¸è¿è¡Œ Stage 3/4 çš„ Parent/Relation è¯„ä¼°ã€‚

    ä½¿ç”¨ Evaluator ç±»è¿›è¡Œ Line-level è¯„ä¼°ï¼ˆå’Œ E2EEvaluationCallback ç›¸åŒçš„è¯„ä¼°é€»è¾‘ï¼‰ã€‚

    ç”¨äº --mode stage1 è®­ç»ƒæ—¶ã€‚
    """

    def __init__(
        self,
        eval_dataloader,
        id2label: Dict[int, str] = None,
        output_dir: str = None,
        trainer=None,  # JointTrainer å®ä¾‹ï¼Œç”¨äºä¿å­˜ best model
    ):
        self.eval_dataloader = eval_dataloader
        self.id2label = id2label
        self.output_dir = output_dir
        self.trainer = trainer

        # Best model é…ç½®ï¼ˆstage1 ç”¨ focus_macro_f1 = mean(F1_section, F1_fstline, F1_paraline)ï¼‰
        self.best_model_metric = "focus_macro_f1"
        self.best_metric_value = float('-inf')
        self.best_step = None

        self.history = []  # [(step, line_macro, line_micro, line_acc, focus_macro), ...]

    def on_evaluate(self, args, state, control, model=None, **kwargs):
        """è¿è¡Œ Stage1 åˆ†ç±»è¯„ä¼°ï¼ˆLine-levelï¼‰"""
        if model is None:
            return

        device = next(model.parameters()).device
        global_step = state.global_step

        logger.info("")
        logger.info("=" * 60)
        logger.info(f"Stage1 Classification Evaluation at Step {global_step}")
        logger.info("=" * 60)

        # ä½¿ç”¨ Evaluator è¿›è¡Œ Line-level è¯„ä¼°ï¼ˆä¸è”åˆè®­ç»ƒè¯„ä¼°ä¸€è‡´ï¼‰
        from .evaluator import Evaluator

        evaluator = Evaluator(model, device)
        output = evaluator.evaluate(
            self.eval_dataloader,
            compute_teds=False,  # Stage1 ä¸è®¡ç®— TEDS
            verbose=True,
            save_predictions=False,
            output_dir=None,
        )

        # æå– Line-level æŒ‡æ ‡
        line_macro = output.line_macro_f1 * 100
        line_micro = output.line_micro_f1 * 100
        line_acc = output.line_accuracy * 100
        focus_macro = output.focus_macro_f1 * 100  # mean(F1_section, F1_fstline, F1_paraline)
        num_lines = output.num_lines

        def fmt_delta(d, threshold=0.5):
            if d >= threshold:
                return f"â†‘{d:+.1f}"
            elif d <= -threshold:
                return f"â†“{d:+.1f}"
            else:
                return f" {d:+.1f}"

        avg_n = min(3, len(self.history))

        logger.info("")
        logger.info("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
        logger.info(f"â•‘        Stage1 Results @ Step {global_step:<6}                        â•‘")
        logger.info("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")

        if avg_n > 0:
            recent = self.history[-avg_n:]
            avg_macro = sum(h[1] for h in recent) / avg_n
            avg_micro = sum(h[2] for h in recent) / avg_n
            avg_acc = sum(h[3] for h in recent) / avg_n
            avg_focus = sum(h[4] for h in recent) / avg_n
            delta_macro = line_macro - avg_macro
            delta_micro = line_micro - avg_micro
            delta_acc = line_acc - avg_acc
            delta_focus = focus_macro - avg_focus

            logger.info(f"â•‘  Metric       â”‚ Current  â”‚  Avg({avg_n})  â”‚  Delta       â•‘")
            logger.info("â•‘â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•‘")
            logger.info(f"â•‘  Macro F1     â”‚  {line_macro:>5.1f}%  â”‚  {avg_macro:>5.1f}%  â”‚  {fmt_delta(delta_macro):>6}      â•‘")
            logger.info(f"â•‘  Focus F1 â˜…   â”‚  {focus_macro:>5.1f}%  â”‚  {avg_focus:>5.1f}%  â”‚  {fmt_delta(delta_focus):>6}      â•‘")
            logger.info(f"â•‘  Micro F1     â”‚  {line_micro:>5.1f}%  â”‚  {avg_micro:>5.1f}%  â”‚  {fmt_delta(delta_micro):>6}      â•‘")
            logger.info(f"â•‘  Accuracy     â”‚  {line_acc:>5.1f}%  â”‚  {avg_acc:>5.1f}%  â”‚  {fmt_delta(delta_acc):>6}      â•‘")
        else:
            logger.info(f"â•‘  Metric       â”‚ Current  â”‚                           â•‘")
            logger.info("â•‘â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•‘")
            logger.info(f"â•‘  Macro F1     â”‚  {line_macro:>5.1f}%  â”‚                           â•‘")
            logger.info(f"â•‘  Focus F1 â˜…   â”‚  {focus_macro:>5.1f}%  â”‚                           â•‘")
            logger.info(f"â•‘  Micro F1     â”‚  {line_micro:>5.1f}%  â”‚                           â•‘")
            logger.info(f"â•‘  Accuracy     â”‚  {line_acc:>5.1f}%  â”‚                           â•‘")

        logger.info("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        logger.info(f"â•‘  Focus F1 = mean(section, fstline, paraline)                 â•‘")
        logger.info(f"â•‘  Lines evaluated: {num_lines:<43} â•‘")
        logger.info("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")

        self.history.append((global_step, line_macro, line_micro, line_acc, focus_macro))

        # Best model ä¿å­˜ï¼ˆstage1 ç”¨ focus_macro_f1ï¼‰
        if self.trainer is not None and self.output_dir is not None:
            self._maybe_save_best_model(
                global_step=global_step,
                metrics={
                    "focus_macro_f1": focus_macro,
                    "line_macro_f1": line_macro,
                    "line_micro_f1": line_micro,
                    "line_accuracy": line_acc,
                },
                model=model,
            )

        # å†™å› metrics dictï¼ˆä¾› Trainer.evaluate() è¿”å›ï¼‰
        metrics_dict = kwargs.get("metrics", {})
        metrics_dict.update({
            "focus_macro_f1": focus_macro / 100,
            "line_macro_f1": line_macro / 100,
            "line_micro_f1": line_micro / 100,
            "line_accuracy": line_acc / 100,
        })

    def _maybe_save_best_model(self, global_step: int, metrics: dict, model):
        """æ£€æŸ¥æ˜¯å¦éœ€è¦ä¿å­˜ best modelï¼ˆæŒ‡æ ‡è¶Šå¤§è¶Šå¥½ï¼‰"""
        current_value = metrics.get(self.best_model_metric, 0.0)

        if current_value > self.best_metric_value:
            self.best_metric_value = current_value
            self.best_step = global_step

            # ä¿å­˜åˆ° output_dir/best/
            best_dir = os.path.join(self.output_dir, "best")
            logger.info(f"")
            logger.info(f"ğŸ† New best model! {self.best_model_metric}={current_value:.2f}% at step {global_step}")
            logger.info(f"   Saving to: {best_dir}")

            # è°ƒç”¨ trainer çš„ä¿å­˜æ–¹æ³•
            self.trainer._save(output_dir=best_dir)

            # ä¿å­˜ best_info.json è®°å½•å…ƒä¿¡æ¯
            import json
            best_info = {
                "step": global_step,
                "metric": self.best_model_metric,
                "value": current_value,
                "all_metrics": metrics,
            }
            with open(os.path.join(best_dir, "best_info.json"), "w") as f:
                json.dump(best_info, f, indent=2)
