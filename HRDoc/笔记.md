# HRDoc 工具文档

## 1. 评估脚本（在 HRDoc/utils/ 下）

| 脚本             | 功能                                              | 输入格式                                                                                                 |
|------------------|---------------------------------------------------|----------------------------------------------------------------------------------------------------------|
| classify_eval.py | Stage 1 评估 - 计算语义分类的 F1                  | 需要 gt_folder 和 pred_folder，每个文件夹包含同名 JSON 文件，每个 JSON 是一个列表，每个元素有 class 字段 |
| teds_eval.py     | 端到端评估 - 计算 TEDS (Tree Edit Distance Score) | 需要 gt_folder 和 pred_folder，JSON 中需要 class, text, parent_id, relation 字段                         |

## 2. 端到端推理流水线（在 HRDoc/end2end_system/ 下）

这是 HRDoc 论文作者提供的**完整推理流水线**，用于处理原始 PDF 并输出结构化文档：

### stage1_data_prepare.py - PDF 解析与 OCR

**功能**：从原始 PDF 提取文本行（content lines）

**流程**：
1. `convert_pdf2img()` - PDF 转图片（使用 fitz/PyMuPDF）
2. `extract_pdf_line()` - 提取文本行及其 bbox（使用 pdfplumber）
3. `find_two_column_spliter()` - 检测双栏布局的分隔位置
4. `merge_cl_lines()` - 合并同一行被拆分的文本
5. `find_bold_section()` - 根据字体粗细识别章节标题

**输出**：`{pdf_name}.raw.json`，每行包含 `text`, `box`, `page`

### stage2_data_prepare.py - 目标检测与合并

**功能**：检测图表/公式并与文本行合并

**依赖**：mmdetection (Cascade R-CNN)

**流程**：
1. 加载 stage1 的 JSON 和图片
2. 使用 Cascade R-CNN 检测 `equation`, `figure`, `table`
3. `gen_renewed_json()` - 将检测框与文本行匹配合并

**输出**：`{pdf_name}.merged.json`

### stage3_inference.py - 端到端结构恢复

**功能**：使用 HRDoc 的端到端模型预测 class + parent + relation

**模型**：`strcut_recover/` 下的自定义模型
- Encoder: 文本 + 视觉特征融合
- Decoder: 同时预测语义类别、父节点、关系类型

**输出**：`pred_result.json`，每行包含：
```json
{
  "text": "...",
  "box": [x0, y0, x1, y1],
  "class": "sec/para/title/...",
  "page": 0,
  "is_meta": false,
  "line_id": 0,
  "parent_id": -1,
  "relation": "contain/equality/connect/meta"
}
```

### stage4_data_postprocess.py - 后处理与结构化输出

**功能**：将行级预测转换为层次化文档结构

**流程**：
1. `transfer_json()` - 根据 parent_id 和 relation 构建树结构
2. `PaperNode` 类 - 递归构建文档节点
3. `gather_text_info()` - 合并 connect 关系的文本

**输出**：层次化 JSON，包含：
```json
{
  "title": ["..."],
  "author": ["..."],
  "sec": [
    {
      "label": "sec",
      "text": "Section Title",
      "child": [
        {"label": "para", "text": "Paragraph content..."}
      ]
    }
  ],
  "fig": [{"box": [...], "caption": "..."}],
  "tab": [{"box": [...], "caption": "..."}]
}
```

## 3. 核心工具脚本（在 HRDoc/utils/ 下）

### classify_eval.py - 语义分类评估

**功能**：计算 Stage 1 语义分类的 F1 分数

**用法**：
```bash
python classify_eval.py --gt_folder <真值目录> --pred_folder <预测目录>
```

**输入格式**：
- gt_folder 和 pred_folder 包含同名 JSON 文件
- 每个 JSON 是列表，每个元素必须有 `class` 字段

**输出**：detailed_f1, macro_f1, micro_f1

**14 个类别**：title, author, mail, affili, section, fstline, paraline, table, figure, caption, equation, footer, header, footnote

### teds_eval.py - 端到端 TEDS 评估

**功能**：计算 TEDS (Tree Edit Distance Score)，评估文档结构重建质量

**用法**：
```bash
python teds_eval.py --gt_folder <真值目录> --pred_folder <预测目录>
```

**输入格式**：
- JSON 文件，每行需要 `class`, `text`, `parent_id`, `relation` 字段

**输出**：macro_teds, micro_teds

**特点**：支持多进程并行计算

### doc_utils.py - 文档树工具

**功能**：文档树相关的工具函数

**核心函数**：
- `tree_edit_distance(pred_tree, true_tree)` - 计算树编辑距离
- `generate_doc_tree_from_log_line_level(texts, parent_idxs, relations)` - 从行级预测构建文档树
- `vis_digraph_py(json_data, out_folder)` - 可视化文档树（生成 graphviz PDF）
- `complete_json(pred_info, gt_info)` - 补全预测 JSON 的 line_id 和 page 字段

**Node 类**：文档树节点，包含 name, children, parent, ref_children, ref_parent, depth 等属性

### utils.py - 通用工具函数

**核心功能**：

1. **PDF 文本提取**：
   - `extract_pdf_line(pdf_path)` - 从 PDF 提取文本行（主入口）
   - `split_pdf_line_by_y()` - 按 Y 坐标分行
   - `split_pdf_line_by_x()` - 按 X 坐标分块

2. **字符串工具**：
   - `cal_wer()` - 计算 WER (Word Error Rate)
   - `find_lcsubstr()` - 最长公共子串
   - `translate_Unicode_latin_ligatures()` - 处理连字符

3. **可视化**：
   - `pdf2img()` - PDF 转图片
   - `title_vis()` - 标注框可视化
   - `visualize()` - 通用可视化

4. **类别映射**：
   - `class2class` - HRDoc 类别到评估类别的映射
   - `trans_class()` - 转换类别（处理 opara 等特殊情况）

## 4. 关键发现

1. **HRDoc 是端到端模型**：一次推理同时输出 class + parent + relation
2. **我们的方案是分阶段的**：
   - Stage 1: LayoutXLM Token Classification (class)
   - Stage 3: ParentFinder (parent_id)
   - Stage 4: RelationClassifier (relation)
3. **评估可以复用**：HRDoc 的 `classify_eval.py` 和 `teds_eval.py` 可以评估我们的输出
4. **后处理可以复用**：`stage4_data_postprocess.py` 的逻辑可以用于我们的推理输出

---

# 附录：数据集构建工具（一般不会使用）

以下工具用于 HRDoc 数据集的构建过程，包括 LaTeX 颜色注入、带颜色 PDF 解析、启发式标注等。
由于我们直接使用已有的 HRDS/HRDH 数据集，这些工具通常不需要使用。

## A1. 数据集构建流程概览

```
LaTeX 源码
    │
    ▼ (pdf_colorization.py)
带颜色标记的 LaTeX
    │
    ▼ (pdflatex 编译)
带颜色的 PDF
    │
    ▼ (extract_pdf_hrds/hrdh.py)
行级 JSON (带 class 标签)
    │
    ▼ (relation_recover.py 或启发式规则)
完整 JSON (带 class + parent_id + relation)
```

## A2. pdf_colorization.py - LaTeX 颜色注入

**功能**：向 LaTeX 源码注入颜色标记，用于生成带标注的 PDF

**流程**：
1. 解析 LaTeX 文件，找到各种命令（\title, \section, \author 等）
2. 在对应位置插入 `\color{MYXXX}` 命令
3. 编译生成带颜色的 PDF

**支持的颜色标记**：
- MYTITLE, MYAUTHOR, MYMAIL, MYAFFILI
- MYSECTION, MYSUBSECTION, MYSUBSUBSECTION
- MYEQU, MYFIG, MYTAB, MYALG
- MYCAP, MYFOOTER, MYPARA, MYREF

**用途**：这是 HRDoc 数据集构建的关键步骤，通过颜色来标注文档元素

**相关 utils.py 函数**：
- `open_tex_file()` - 读取并去除注释
- `get_main_tex_path()` - 找到主 tex 文件
- `Left_Brace` / `Begin_Brace` 类 - 括号匹配

## A3. extract_pdf_hrds.py - HRDS 数据提取

**功能**：从带颜色标注的 PDF 中提取 HRDS 数据集

**适用**：HRDoc-Simple (ACL 会议论文，单栏布局)

**流程**：
1. PDF 转图片
2. 使用 pdfplumber 提取文本行和字符颜色
3. 根据字符颜色判断语义类别（通过 LaTeX 编译时插入的颜色）
4. 检测双栏分隔、合并文本行、识别章节、页眉页脚等
5. 输出 JSON 格式的标注数据

**DocParser 类**：封装了 PDF 解析的完整流程

**启发式规则**：
- `find_two_column_spliter()` - 统计 X 坐标分布，找双栏分隔点
- `merge_cl_lines()` - 合并 Y 坐标相近的文本行
- `find_bold_section()` - 根据字体粗细识别章节标题
- `find_ele_box_in_area()` - 在指定区域内搜索图表
- `find_cl_in_area()` - 在指定区域内搜索文本行

## A4. extract_pdf_hrdh.py - HRDH 数据提取

**功能**：从带颜色标注的 PDF 中提取 HRDH 数据集

**适用**：HRDoc-Hard (多种来源的论文，复杂布局)

**与 HRDS 的区别**：
- 处理更复杂的布局（多栏、混合布局）
- 更多的后处理规则
- 支持更多元素类型（Algorithm, Equation_Label 等）

**额外的启发式规则**：
- `merge_cls()` - 合并多个文本行
- `merge_connect()` - 合并 connect 关系的行

## A5. relation_recover.py - 启发式关系恢复

**功能**：从 XML 标注文件恢复父子关系和关系类型

**流程**：
1. `xml2json()` - 解析单页 XML 标注
2. `folder2json()` - 合并多页 XML 为一个文档 JSON
3. `find_parent()` - 根据规则推断 parent_id 和 relation

**关系类型**：
- `meta` - 元信息节点（title, author 等）
- `contain` - 包含关系（section 包含 paragraph）
- `connect` - 连接关系（同一段落的续行）
- `equality` - 平级关系（同级 section）

**xmllabel 层级定义**：

| 类别 | level | 说明 |
|------|-------|------|
| title, author, affili, mail, fnote, header, foot | 0 | 元信息 |
| fig, tab | 0 | 图表 |
| sec1 | 1 | 一级标题 |
| sec2 | 2 | 二级标题 |
| sec3 | 3 | 三级标题 |
| fstline | 5 | 段落首行 |
| para, equ | 6 | 段落行、公式 |
| figcap, tabcap | 7 | 图表标题 |
| opara | 8 | Section 内无标题段落 |

**启发式父节点查找规则**（`prev_low_level()` 函数）：
1. 向前遍历，找到 level ≤ 当前节点的第一个非 meta 节点
2. 同 level：
   - sec/fstline → `equality`
   - para/equ → `connect`
3. 更高 level（当前 level > 前节点 level）：
   - sec/fstline → `contain`
   - para/equ → `connect`

**特殊处理**：
- figcap → 在同页找最近的 fig
- tabcap → 在同页找最近的 tab
- fig/tab → 在同页找最近的 figcap/tabcap
